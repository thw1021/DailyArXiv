# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2025-10-03

## Fluid Dynamics
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark](http://arxiv.org/abs/2509.26574v2)** | 2025-10-01 | <details><summary>Show</summary><p>While large language models (LLMs) with reasoning capabilities are progressing rapidly on high-school math competitions and coding, can they reason effectively through complex, open-ended challenges found in frontier physics research? And crucially, what kinds of reasoning tasks do physicists want LLMs to assist with? To address these questions, we present the CritPt (Complex Research using Integrated Thinking - Physics Test, pronounced "critical point"), the first benchmark designed to test LLMs on unpublished, research-level reasoning tasks that broadly covers modern physics research areas, including condensed matter, quantum physics, atomic, molecular & optical physics, astrophysics, high energy physics, mathematical physics, statistical physics, nuclear physics, nonlinear dynamics, fluid dynamics and biophysics. CritPt consists of 71 composite research challenges designed to simulate full-scale research projects at the entry level, which are also decomposed to 190 simpler checkpoint tasks for more fine-grained insights. All problems are newly created by 50+ active physics researchers based on their own research. Every problem is hand-curated to admit a guess-resistant and machine-verifiable answer and is evaluated by an automated grading pipeline heavily customized for advanced physics-specific output formats. We find that while current state-of-the-art LLMs show early promise on isolated checkpoints, they remain far from being able to reliably solve full research-scale challenges: the best average accuracy among base models is only 4.0% , achieved by GPT-5 (high), moderately rising to around 10% when equipped with coding tools. Through the realistic yet standardized evaluation offered by CritPt, we highlight a large disconnect between current model capabilities and realistic physics research demands, offering a foundation to guide the development of scientifically grounded AI tools.</p></details> | <details><summary>39 pa...</summary><p>39 pages, 6 figures, 6 tables</p></details> |
| **[Foam-Agent 2.0: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM](http://arxiv.org/abs/2509.18178v2)** | 2025-09-30 | <details><summary>Show</summary><p>Computational Fluid Dynamics (CFD) is an essential simulation tool in engineering, yet its steep learning curve and complex manual setup create significant barriers. To address these challenges, we introduce Foam-Agent, a multi-agent framework that automates the entire end-to-end OpenFOAM workflow from a single natural language prompt. Our key innovations address critical gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation: Foam-Agent is the first system to manage the full simulation pipeline, including advanced pre-processing with a versatile Meshing Agent capable of handling external mesh files and generating new geometries via Gmsh, automatic generation of HPC submission scripts, and post-simulation visualization via ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent, the framework uses Model Context Protocol (MCP) to expose its core functions as discrete, callable tools. This allows for flexible integration and use by other agentic systems, such as Claude-code, for more exploratory workflows. 3. High-Fidelity Configuration Generation: We achieve superior accuracy through a Hierarchical Multi-Index RAG for precise context retrieval and a dependency-aware generation process that ensures configuration consistency. Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2% success rate with Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the expertise barrier for CFD, demonstrating how specialized multi-agent systems can democratize complex scientific computing. The code is public at https://github.com/csml-rpi/Foam-Agent.</p></details> |  |
| **[InverseBench: Benchmarking Plug-and-Play Diffusion Priors for Inverse Problems in Physical Sciences](http://arxiv.org/abs/2503.11043v2)** | 2025-09-30 | <details><summary>Show</summary><p>Plug-and-play diffusion priors (PnPDP) have emerged as a promising research direction for solving inverse problems. However, current studies primarily focus on natural image restoration, leaving the performance of these algorithms in scientific inverse problems largely unexplored. To address this gap, we introduce \textsc{InverseBench}, a framework that evaluates diffusion models across five distinct scientific inverse problems. These problems present unique structural challenges that differ from existing benchmarks, arising from critical scientific applications such as optical tomography, medical imaging, black hole imaging, seismology, and fluid dynamics. With \textsc{InverseBench}, we benchmark 14 inverse problem algorithms that use plug-and-play diffusion priors against strong, domain-specific baselines, offering valuable new insights into the strengths and weaknesses of existing algorithms. To facilitate further research and development, we open-source the codebase, along with datasets and pre-trained models, at https://devzhk.github.io/InverseBench/.</p></details> |  |
| **[Cross-Model Verification of Wall-Bounded Flows using Finite-JAX](http://arxiv.org/abs/2509.25569v1)** | 2025-09-29 | <details><summary>Show</summary><p>Accurate prediction of wall-bounded flows remains central to advancing both theoretical understanding and computational methods in fluid mechanics. In this study, we perform a numerical simulation of channel flow using a complementary approach: a high-performance, differentiable finite-difference solver developed in JAX (Finite-JAX) and an analytical solution derived from the Navier-Stokes Equations, also referred to as the Hagen-Poiseuille equation. The solver is applied to the incompressible Navier-Stokes equations, along with appropriate boundary conditions, to capture canonical flow features such as velocity profiles and pressure gradients. Cross-model verification is conducted by systematically comparing numerical results between Finite-JAX and the analytical solution, with a focus on velocity distributions. In addition, numerical results are benchmarked against analytical solutions for laminar regimes, allowing for the direct quantification of verification accuracy errors. Our findings demonstrate that cross-model verification not only strengthens confidence in simulation fidelity but also provides a pathway for integrating differentiable solvers with established computational fluid dynamics platforms, paving the way for future fluid flow research.</p></details> | 9 pages |
| **[Diffuse Domain Methods with Dirichlet Boundary Conditions](http://arxiv.org/abs/2509.25115v1)** | 2025-09-29 | <details><summary>Show</summary><p>The solution of partial differential equations (PDEs) on complex domains often presents a significant computational challenge by requiring the generation of fitted meshes. The Diffuse Domain Method (DDM) is an alternative which reformulates the problem on a larger, simple domain where the complex geometry is represented by a smooth phase-field function. This paper introduces and analyses several new DDM methods for solving problems with Dirichlet boundary conditions. We derive two new methods from the mixed formulation of the governing equations. This approach transforms the essential Dirichlet conditions into natural boundary conditions. Additionally, we develop coercive formulations based on Nitsche's method, and provide proofs of coercivity for all new and key existing approximations. Numerical experiments demonstrate the improved accuracy of the new methods, and reveal the balance between $L^2$ and $H^1$ errors. The practical effectiveness of this approach is demonstrated through the simulation of the incompressible Navier-Stokes equations on a benchmark fluid dynamics problems.</p></details> |  |
| **[Towards a Certificate of Trust: Task-Aware OOD Detection for Scientific AI](http://arxiv.org/abs/2509.25080v1)** | 2025-09-29 | <details><summary>Show</summary><p>Data-driven models are increasingly adopted in critical scientific fields like weather forecasting and fluid dynamics. These methods can fail on out-of-distribution (OOD) data, but detecting such failures in regression tasks is an open challenge. We propose a new OOD detection method based on estimating joint likelihoods using a score-based diffusion model. This approach considers not just the input but also the regression model's prediction, providing a task-aware reliability score. Across numerous scientific datasets, including PDE datasets, satellite imagery and brain tumor segmentation, we show that this likelihood strongly correlates with prediction error. Our work provides a foundational step towards building a verifiable 'certificate of trust', thereby offering a practical tool for assessing the trustworthiness of AI-based scientific predictions. Our code is publicly available at https://github.com/bogdanraonic3/OOD_Detection_ScientificML</p></details> |  |
| **[Learning to Solve Optimization Problems Constrained with Partial Differential Equations](http://arxiv.org/abs/2509.24573v1)** | 2025-09-29 | <details><summary>Show</summary><p>Partial differential equation (PDE)-constrained optimization arises in many scientific and engineering domains, such as energy systems, fluid dynamics and material design. In these problems, the decision variables (e.g., control inputs or design parameters) are tightly coupled with the PDE state variables, and the feasible set is implicitly defined by the governing PDE constraints. This coupling makes the problems computationally demanding, as it requires handling high dimensional discretization and dynamic constraints. To address these challenges, this paper introduces a learning-based framework that integrates a dynamic predictor with an optimization surrogate. The dynamic predictor, a novel time-discrete Neural Operator (Lu et al.), efficiently approximate system trajectories governed by PDE dynamics, while the optimization surrogate leverages proxy optimizer techniques (Kotary et al.) to approximate the associated optimal decisions. This dual-network design enables real-time approximation of optimal strategies while explicitly capturing the coupling between decisions and PDE dynamics. We validate the proposed approach on benchmark PDE-constrained optimization tasks inlacing Burgers' equation, heat equation and voltage regulation, and demonstrate that it achieves solution quality comparable to classical control-based algorithms, such as the Direct Method and Model Predictive Control (MPC), while providing up to four orders of magnitude improvement in computational speed.</p></details> |  |
| **[Code2MCP: Transforming Code Repositories into MCP Services](http://arxiv.org/abs/2509.05941v2)** | 2025-09-28 | <details><summary>Show</summary><p>The Model Context Protocol (MCP) aims to create a standard for how Large Language Models use tools. However, most current research focuses on selecting tools from an existing pool. A more fundamental, yet largely overlooked, problem is how to populate this pool by converting the vast number of existing software projects into MCP-compatible services. To bridge this gap, we introduce Code2MCP, an agent-based framework that automatically transforms a GitHub repository into a functional MCP service with minimal human intervention. Code2MCP employs a multi-agent workflow for code analysis, environment setup, tool function design, and service generation, enhanced by a self-correcting loop to ensure reliability. We demonstrate that Code2MCP successfully transforms open-source computing libraries in scientific fields such as bioinformatics, mathematics, and fluid dynamics that are not available in existing MCP servers. By providing a novel automated pathway to unlock GitHub, the world's largest code repository, for the MCP ecosystem, Code2MCP serves as a catalyst to significantly accelerate the protocol's adoption and practical application. The code is public at https://github.com/DEFENSE-SEU/Code2MCP.</p></details> |  |
| **[Reversible GNS for Dissipative Fluids with Consistent Bidirectional Dynamics](http://arxiv.org/abs/2509.22207v1)** | 2025-09-26 | <details><summary>Show</summary><p>Simulating physically plausible trajectories toward user-defined goals is a fundamental yet challenging task in fluid dynamics. While particle-based simulators can efficiently reproduce forward dynamics, inverse inference remains difficult, especially in dissipative systems where dynamics are irreversible and optimization-based solvers are slow, unstable, and often fail to converge. In this work, we introduce the Reversible Graph Network Simulator (R-GNS), a unified framework that enforces bidirectional consistency within a single graph architecture. Unlike prior neural simulators that approximate inverse dynamics by fitting backward data, R-GNS does not attempt to reverse the underlying physics. Instead, we propose a mathematically invertible design based on residual reversible message passing with shared parameters, coupling forward dynamics with inverse inference to deliver accurate predictions and efficient recovery of plausible initial states. Experiments on three dissipative benchmarks (Water-3D, WaterRamps, and WaterDrop) show that R-GNS achieves higher accuracy and consistency with only one quarter of the parameters, and performs inverse inference more than 100 times faster than optimization-based baselines. For forward simulation, R-GNS matches the speed of strong GNS baselines, while in goal-conditioned tasks it eliminates iterative optimization and achieves orders-of-magnitude speedups. On goal-conditioned tasks, R-GNS further demonstrates its ability to complex target shapes (e.g., characters "L" and "N") through vivid, physically consistent trajectories. To our knowledge, this is the first reversible framework that unifies forward and inverse simulation for dissipative fluid systems.</p></details> | 13 pages, 5 figures |
| **[ChaosNexus: A Foundation Model for Universal Chaotic System Forecasting with Multi-scale Representations](http://arxiv.org/abs/2509.21802v1)** | 2025-09-26 | <details><summary>Show</summary><p>Accurately forecasting chaotic systems, prevalent in domains such as weather prediction and fluid dynamics, remains a significant scientific challenge. The inherent sensitivity of these systems to initial conditions, coupled with a scarcity of observational data, severely constrains traditional modeling approaches. Since these models are typically trained for a specific system, they lack the generalization capacity necessary for real-world applications, which demand robust zero-shot or few-shot forecasting on novel or data-limited scenarios. To overcome this generalization barrier, we propose ChaosNexus, a foundation model pre-trained on a diverse corpus of chaotic dynamics. ChaosNexus employs a novel multi-scale architecture named ScaleFormer augmented with Mixture-of-Experts layers, to capture both universal patterns and system-specific behaviors. The model demonstrates state-of-the-art zero-shot generalization across both synthetic and real-world benchmarks. On a large-scale testbed comprising over 9,000 synthetic chaotic systems, it improves the fidelity of long-term attractor statistics by more than 40% compared to the leading baseline. This robust performance extends to real-world applications with exceptional data efficiency. For instance, in 5-day global weather forecasting, ChaosNexus achieves a competitive zero-shot mean error below 1 degree, a result that further improves with few-shot fine-tuning. Moreover, experiments on the scaling behavior of ChaosNexus provide a guiding principle for scientific foundation models: cross-system generalization stems from the diversity of training systems, rather than sheer data volume.</p></details> |  |
| **[Analysis and Simulation of a Fluid-Heat System in a Thin, Rough Layer in Contact With a Solid Bulk Domain](http://arxiv.org/abs/2406.02150v3)** | 2025-09-25 | <details><summary>Show</summary><p>We investigate the effective coupling between heat and fluid dynamics within a thin fluid layer in contact with a solid structure via a rough surface. Moreover, the opposing vertical surfaces of the thin layer are in relative motion. This setup is particularly relevant to grinding processes, where cooling lubricants interact with the rough surface of a rotating grinding wheel. The resulting model is non-linearly coupled through(i) temperature-dependent viscosity and (ii) convective heat transport. The underlying geometry is highly heterogeneous due to the thin, rough surface characterized by a small parameter representing both the height of the layer and the periodicity of the roughness. We analyze this non-linear system for existence, uniqueness, and energy estimates and study the limit behavior within the framework of two-scale convergence in thin domains. In this limit, we derive an effective interface model in 3D (a line in 2D) for the heat and fluid interactions inside the fluid. We implement the system numerically and validate the limit problem through direct comparison with the micromodel. Additionally, we investigate the influence of the temperature-dependent viscosity and various geometrical configurations via simulation experiments. The corresponding numerical code is freely available on GitHub.</p></details> |  |
| **[A Reformulation of UVN-Flash for Multicomponent Two-Phase Systems with Application to CO2-rich Mixture Transport in Pipelines](http://arxiv.org/abs/2509.20965v1)** | 2025-09-25 | <details><summary>Show</summary><p>Pipeline transport of dense-phase CO2-rich mixtures is a crucial component in carbon capture and storage (CCS). Accurate modeling requires coupling of fluid dynamics and thermodynamics, especially during transient events such as depressurization. In this work, we present a unified framework for two-phase multicomponent transport in pipelines that integrates both aspects. Specifically, we employ the homogeneous equilibrium model (HEM) for modeling the transport of two-phase CO2-rich mixture, with thermodynamic closure provided by a Helmholtz energy-based equation of state. Phase equilibrium calculations are performed using UVN-flash, supplemented with a stability analysis procedure to detect phase separation and generate initial guesses for the phase-equilibrium calculations. Specifically, we introduce a novel tailored UVN-flash routine that aligns with the fluid dynamics formulation. This is achieved by introducing an alternative and better-scaled set of variables for the phase-equilibrium calculations. The proposed framework is applied to the depressurization of tanks and pipelines containing CO2-rich mixtures, demonstrating its effectiveness for CCS-relevant applications.</p></details> | <details><summary>29 pa...</summary><p>29 pages, 11 figures, 4 appendicies</p></details> |
| **[A Fourier/Modal-Spectral-Element Method for the Simulation of High-Reynolds Number Incompressible Stratified Flows in Domains with a Single Non-Periodic Direction](http://arxiv.org/abs/2509.20833v1)** | 2025-09-25 | <details><summary>Show</summary><p>We present the components of a high-order accurate Navier-Stokes solver designed to simulate high-Reynolds-number stratified flows. The proposed numerical model addresses some of the numerical and computational challenges that high-Reynolds-number simulations pose, facilitating the reproduction of stratified turbulent fluid dynamics typically observed in oceanic and atmospheric flows, namely the development of thin regions of high vertical shear, strongly layered turbulence at high Reynolds numbers and internal wave radiation. This Navier-Stokes solver utilizes a Fourier pseudo-spectral method in the horizontal direction and a modal spectral element discretization in the vertical. We adopt an implicit-explicit time discretization scheme that involves solving several one-dimensional Helmholtz problems at each time step. Static condensation and modal boundary-adapted basis functions result in an inexpensive algorithm based on solving many small tridiagonal systems. A series of benchmark studies is presented to demonstrate the robustness of the flow solver. These include two-dimensional and three-dimensional problems, concluding with a turbulent stratified wake generated by a sphere in linear stratification.</p></details> | 41 pages, 24 figures |
| **[MDBench: Benchmarking Data-Driven Methods for Model Discovery](http://arxiv.org/abs/2509.20529v1)** | 2025-09-24 | <details><summary>Show</summary><p>Model discovery aims to uncover governing differential equations of dynamical systems directly from experimental data. Benchmarking such methods is essential for tracking progress and understanding trade-offs in the field. While prior efforts have focused mostly on identifying single equations, typically framed as symbolic regression, there remains a lack of comprehensive benchmarks for discovering dynamical models. To address this, we introduce MDBench, an open-source benchmarking framework for evaluating model discovery methods on dynamical systems. MDBench assesses 12 algorithms on 14 partial differential equations (PDEs) and 63 ordinary differential equations (ODEs) under varying levels of noise. Evaluation metrics include derivative prediction accuracy, model complexity, and equation fidelity. We also introduce seven challenging PDE systems from fluid dynamics and thermodynamics, revealing key limitations in current methods. Our findings illustrate that linear methods and genetic programming methods achieve the lowest prediction error for PDEs and ODEs, respectively. Moreover, linear models are in general more robust against noise. MDBench accelerates the advancement of model discovery methods by offering a rigorous, extensible benchmarking framework and a rich, diverse collection of dynamical system datasets, enabling systematic evaluation, comparison, and improvement of equation accuracy and robustness.</p></details> |  |
| **[xGFabric: Coupling Sensor Networks and HPC Facilities with Private 5G Wireless Networks for Real-Time Digital Agriculture](http://arxiv.org/abs/2509.20340v1)** | 2025-09-24 | <details><summary>Show</summary><p>Advanced scientific applications require coupling distributed sensor networks with centralized high-performance computing facilities. Citrus Under Protective Screening (CUPS) exemplifies this need in digital agriculture, where citrus research facilities are instrumented with numerous sensors monitoring environmental conditions and detecting protective screening damage. CUPS demands access to computational fluid dynamics codes for modeling environmental conditions and guiding real-time interventions like water application or robotic repairs. These computing domains have contrasting properties: sensor networks provide low-performance, limited-capacity, unreliable data access, while high-performance facilities offer enormous computing power through high-latency batch processing. Private 5G networks present novel capabilities addressing this challenge by providing low latency, high throughput, and reliability necessary for near-real-time coupling of edge sensor networks with HPC simulations. This work presents xGFabric, an end-to-end system coupling sensor networks with HPC facilities through Private 5G networks. The prototype connects remote sensors via 5G network slicing to HPC systems, enabling real-time digital agriculture simulation.</p></details> | <details><summary>8 pag...</summary><p>8 pages with 7 figures followed by 3 pages of reproducibility appendix. This paper will be published following the SC 2025 conference on November 16-21, 2025 at St Louis, MO, USA. ISBN: 978-8-4007-1871-7/2025/11</p></details> |
| **[Impact of Loss Weight and Model Complexity on Physics-Informed Neural Networks for Computational Fluid Dynamics](http://arxiv.org/abs/2509.21393v1)** | 2025-09-24 | <details><summary>Show</summary><p>Physics Informed Neural Networks offer a mesh free framework for solving PDEs but are highly sensitive to loss weight selection. We propose two dimensional analysis based weighting schemes, one based on quantifiable terms, and another also incorporating unquantifiable terms for more balanced training. Benchmarks on heat conduction, convection diffusion, and lid driven cavity flows show that the second scheme consistently improves stability and accuracy over equal weighting. Notably, in high Peclet number convection diffusion, where traditional solvers fail, PINNs with our scheme achieve stable, accurate predictions, highlighting their robustness and generalizability in CFD problems.</p></details> |  |
| **[Model-Agnostic AI Framework with Explicit Time Integration for Long-Term Fluid Dynamics Prediction](http://arxiv.org/abs/2412.05657v4)** | 2025-09-24 | <details><summary>Show</summary><p>This study addresses the critical challenge of error accumulation in spatio-temporal auto-regressive (AR) predictions within scientific machine learning models by exploring temporal integration schemes and adaptive multi-step rollout strategies. We introduce the first implementation of the two-step Adams-Bashforth method specifically tailored for data-driven AR prediction, leveraging historical derivative information to enhance numerical stability without additional computational overhead. To validate our approach, we systematically evaluate time integration schemes across canonical 2D PDEs before extending to complex Navier-Stokes cylinder vortex shedding dynamics. Additionally, we develop three novel adaptive weighting strategies that dynamically adjust the importance of different future time steps during multi-step rollout training. Our analysis reveals that as physical complexity increases, such sophisticated rollout techniques become essential, with the Adams-Bashforth scheme demonstrating consistent robustness across investigated systems and our best adaptive approach delivering an 89% improvement over conventional fixed-weight methods while maintaining similar computational costs. For the complex Navier-Stokes vortex shedding problem, despite using an extremely lightweight graph neural network with just 1,177 trainable parameters and training on only 50 snapshots, our framework accurately predicts 350 future time steps reducing mean squared error from 0.125 (single-step direct prediction) to 0.002 (Adams-Bashforth with proposed multi-step rollout). Our integrated methodology demonstrates an 83% improvement over standard noise injection techniques and maintains robustness under severe spatial constraints; specifically, when trained on only a partial spatial domain, it still achieves 58% and 27% improvements over direct prediction and forward Euler methods, respectively.</p></details> |  |
| **[GradNetOT: Learning Optimal Transport Maps with GradNets](http://arxiv.org/abs/2507.13191v2)** | 2025-09-23 | <details><summary>Show</summary><p>Monotone gradient functions play a central role in solving the Monge formulation of the optimal transport (OT) problem, which arises in modern applications ranging from fluid dynamics to robot swarm control. When the transport cost is the squared Euclidean distance, Brenier's theorem guarantees that the unique optimal transport map satisfies a Monge-Amp\`ere equation and is the gradient of a convex function. In [arXiv:2301.10862] [arXiv:2404.07361], we proposed Monotone Gradient Networks (mGradNets), neural networks that directly parameterize the space of monotone gradient maps. In this work, we leverage mGradNets to directly learn the optimal transport mapping by minimizing a training loss function defined using the Monge-Amp\`ere equation. We empirically show that the structural bias of mGradNets facilitates the learning of optimal transport maps across both image morphing tasks and high-dimensional OT problems.</p></details> | <details><summary>CAMSA...</summary><p>CAMSAP 2025 Camera-Ready Version</p></details> |
| **[A Divergence-free Preserving Mixed Finite Element Method for Thermally Driven Active Fluid Model](http://arxiv.org/abs/2509.19053v1)** | 2025-09-23 | <details><summary>Show</summary><p>In this report, we propose a divergence-free preserving mixed finite element method (FEM) for the system of nonlinear fourth-order thermally driven active fluid equations. By introducing two auxiliary variables, we lower the complexity of the model and enhance the robustness of the algorithm. The auxiliary variable $w = \Delta u$ is used to convert the original fourth-order system to an equivalent system of second-order equations, thereby easing the regularity constraints imposed on standard $H^2$-conforming finite element space. The second variable $\eta$, analogous to the pressure, helps the scheme preserve the divergence-free condition arising from the model. The two-step Dahlquist-Liniger-Nevanlinna (DLN) time integrator, unconditionally non-linear stable and second-order accurate under non-uniform time grids, is combined with the mixed FEM for fully discrete approximation. Due to the fine properties of the DLN scheme, we prove the boundedness of model energy and the associated error estimates under suitable regularity assumptions and mild time restrictions. Additionally, an adaptive time-stepping strategy based on a minimum-dissipation criterion is to balance computational costs and time efficiency. Several numerical experiments validate the theoretical findings and demonstrate the method's effectiveness and accuracy in simulating complex active fluid dynamics.</p></details> |  |
| **[Quasi Steady-State Frequency](http://arxiv.org/abs/2505.21461v5)** | 2025-09-22 | <details><summary>Show</summary><p>Accurate frequency estimation is critical for the control, monitoring and protection of electrical power systems, in particular, of systems with a high penetration of power electronics. This paper introduces the novel concept of Quasi Steady-State (QSS) frequency as a quantity that fills the gap between stationary and instantaneous frequency. QSS frequency coincides with the fundamental frequency of an AC voltage in any stationary conditions, including unbalanced and non-sinusoidal, and is able to capture the time-varying fundamental frequency in transient conditions. The paper also proposes a metric borrowed from fluid dynamics, namely, the time derivative of the circulation, to define the scope of validity of the QSS frequency. Analytical examples as well as a case study based on a fully-fledged EMT model of the IEEE 39-bus system serve to illustrate, respectively, the properties of the QSS frequency and its behavior in transient conditions.</p></details> |  |
| **[nDNA -- the Semantic Helix of Artificial Cognition](http://arxiv.org/abs/2509.18216v1)** | 2025-09-21 | <details><summary>Show</summary><p>As AI foundation models grow in capability, a deeper question emerges: What shapes their internal cognitive identity -- beyond fluency and output? Benchmarks measure behavior, but the soul of a model resides in its latent geometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic representation that captures this latent identity through the intrinsic geometry of belief. At its core, nDNA is synthesized from three principled and indispensable dimensions of latent geometry: spectral curvature, which reveals the curvature of conceptual flow across layers; thermodynamic length, which quantifies the semantic effort required to traverse representational transitions through layers; and belief vector field, which delineates the semantic torsion fields that guide a model's belief directional orientations. Like biological DNA, it encodes ancestry, mutation, and semantic inheritance, found in finetuning and alignment scars, cultural imprints, and architectural drift. In naming it, we open a new field: Neural Genomics, where models are not just tools, but digital semantic organisms with traceable inner cognition. Modeling statement. We read AI foundation models as semantic fluid dynamics: meaning is transported through layers like fluid in a shaped conduit; nDNA is the physics-grade readout of that flow -- a geometry-first measure of how meaning is bent, paid for, and pushed -- yielding a stable, coordinate-free neural DNA fingerprint tied to on-input behavior; with this fingerprint we cross into biology: tracing lineages across pretraining, fine-tuning, alignment, pruning, distillation, and merges; measuring inheritance between checkpoints; detecting drift as traits shift under new data or objectives; and, ultimately, studying the evolution of artificial cognition to compare models, diagnose risks, and govern change over time.</p></details> |  |
| **[LVADNet3D: A Deep Autoencoder for Reconstructing 3D Intraventricular Flow from Sparse Hemodynamic Data](http://arxiv.org/abs/2509.16860v1)** | 2025-09-21 | <details><summary>Show</summary><p>Accurate assessment of intraventricular blood flow is essential for evaluating hemodynamic conditions in patients supported by Left Ventricular Assist Devices (LVADs). However, clinical imaging is either incompatible with LVADs or yields sparse, low-quality velocity data. While Computational Fluid Dynamics (CFD) simulations provide high-fidelity data, they are computationally intensive and impractical for routine clinical use. To address this, we propose LVADNet3D, a 3D convolutional autoencoder that reconstructs full-resolution intraventricular velocity fields from sparse velocity vector inputs. In contrast to a standard UNet3D model, LVADNet3D incorporates hybrid downsampling and a deeper encoder-decoder architecture with increased channel capacity to better capture spatial flow patterns. To train and evaluate the models, we generate a high-resolution synthetic dataset of intraventricular blood flow in LVAD-supported hearts using CFD simulations. We also investigate the effect of conditioning the models on anatomical and physiological priors. Across various input configurations, LVADNet3D outperforms the baseline UNet3D model, yielding lower reconstruction error and higher PSNR results.</p></details> | <details><summary>Accep...</summary><p>Accepted to International Conference on Machine Learning and Applications (ICMLA), 6 pages, 4 figure, 3 tables</p></details> |
| **[CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](http://arxiv.org/abs/2509.20374v1)** | 2025-09-19 | <details><summary>Show</summary><p>Large Language Models (LLMs) have demonstrated strong performance across general NLP tasks, but their utility in automating numerical experiments of complex physical system -- a critical and labor-intensive component -- remains underexplored. As the major workhorse of computational science over the past decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging testbed for evaluating the scientific capabilities of LLMs. We introduce CFDLLMBench, a benchmark suite comprising three complementary components -- CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM performance across three key competencies: graduate-level CFD knowledge, numerical and physical reasoning of CFD, and context-dependent implementation of CFD workflows. Grounded in real-world CFD practices, our benchmark combines a detailed task taxonomy with a rigorous evaluation framework to deliver reproducible results and quantify LLM performance across code executability, solution accuracy, and numerical convergence behavior. CFDLLMBench establishes a solid foundation for the development and evaluation of LLM-driven automation of numerical experiments for complex physical systems. Code and data are available at https://github.com/NREL-Theseus/cfdllmbench/.</p></details> |  |
| **[Discrete Empirical Interpolation Method with Upper and Lower Bound Constraints](http://arxiv.org/abs/2509.16018v1)** | 2025-09-19 | <details><summary>Show</summary><p>Discrete Empirical Interpolation Method (DEIM) is a simple and effective method for reconstructing a function from its incomplete pointwise observations. However, applying DEIM to functions with physically constrained ranges can produce reconstructions with values outside the prescribed physical bounds. Such physically constrained quantities occur routinely in applications, e.g., mass density whose range is nonnegative. The DEIM reconstructions which violate these physical constraints are not usable in downstream tasks such as forecasting and control. To address this issue, we develop Constrained DEIM (C-DEIM) whose reconstructions are guaranteed to respect the physical bounds of the quantity of interest. C-DEIM enforces the bounds as soft constraints, in the form of a carefully designed penalty term, added to the underlying least squares problem. We prove that the C-DEIM reconstructions satisfy the physical constraints asymptotically, i.e., as the penalty parameter increases towards infinity. We also derive a quantitative upper bound for the observation residual of C-DEIM. Based on these theoretical results, we devise an efficient algorithm for practical implementation of C-DEIM. The efficacy of the method and the accompanying algorithm are demonstrated on several examples, including a heat transfer problem from fluid dynamics and a cellular automaton model of wildfire spread.</p></details> |  |
| **[GridapROMs.jl: Efficient reduced order modelling in the Julia programming language](http://arxiv.org/abs/2503.15994v3)** | 2025-09-18 | <details><summary>Show</summary><p>In this paper, we introduce GridapROMs, a Julia-based library for the numerical approximation of parameterized partial differential equations (PDEs) using a comprehensive suite of linear reduced order models (ROMs). The library is designed to be extendable and productive, leveraging an expressive high-level API built on the Gridap PDE solver backend, while achieving high performance through Julia's just-in-time compiler and advanced lazy evaluation techniques. GridapROMs is PDE-agnostic, enabling its application to a wide range of problems, including linear, nonlinear, single-field, multi-field, steady, and unsteady equations. This work details the library's key innovations, implementation principles, and core components, providing usage examples and demonstrating its capabilities by solving a fluid dynamics problem modeled by the Navier-Stokes equations in a 3D geometry.</p></details> | 14 pages, 6 figures |
| **[Performance measurements of modern Fortran MPI applications with Score-P](http://arxiv.org/abs/2508.16592v2)** | 2025-09-17 | <details><summary>Show</summary><p>Version 3.0 of the Message-Passing Interface (MPI) standard, released in 2012, introduced a new set of language bindings for Fortran 2008. By making use of modern language features and the enhanced interoperability with C, there was finally a type safe and standard conforming method to call MPI from Fortran. This highly recommended use mpi_f08 language binding has since then been widely adopted among developers of modern Fortran applications. However, tool support for the F08 bindings is still lacking almost a decade later, forcing users to recede to the less safe and convenient interfaces. Full support for the F08 bindings was added to the performance measurement infrastructure Score-P by implementing MPI wrappers in Fortran. Wrappers cover the latest MPI standard version 4.1 in its entirety, matching the features of the C wrappers. By implementing the wrappers in modern Fortran, we can provide full support for MPI procedures passing attributes, info objects, or callbacks. The implementation is regularly tested under the MPICH test suite. The new F08 wrappers were already used by two fluid dynamics simulation codes -- Neko, a spectral finite-element code derived from Nek5000, and EPIC (Elliptical Parcel-In-Cell) -- to successfully generate performance measurements. In this work, we additionally present our design considerations and sketch out the implementation, discussing the challenges we faced in the process. The key component of the implementation is a code generator that produces approximately 50k lines of MPI wrapper code to be used by Score-P, relying on the Python pympistandard module to provide programmatic access to the extracted data from the MPI standard.</p></details> |  |
| **[A reduced-order derivative-informed neural operator for subsurface fluid-flow](http://arxiv.org/abs/2509.13620v1)** | 2025-09-17 | <details><summary>Show</summary><p>Neural operators have emerged as cost-effective surrogates for expensive fluid-flow simulators, particularly in computationally intensive tasks such as permeability inversion from time-lapse seismic data, and uncertainty quantification. In these applications, the fidelity of the surrogate's gradients with respect to system parameters is crucial, as the accuracy of downstream tasks, such as optimization and Bayesian inference, relies directly on the quality of the derivative information. Recent advances in physics-informed methods have leveraged derivative information to improve surrogate accuracy. However, incorporating explicit Jacobians can become computationally prohibitive, as the complexity typically scales quadratically with the number of input parameters. To address this limitation, we propose DeFINO (Derivative-based Fisher-score Informed Neural Operator), a reduced-order, derivative-informed training framework. DeFINO integrates Fourier neural operators (FNOs) with a novel derivative-based training strategy guided by the Fisher Information Matrix (FIM). By projecting Jacobians onto dominant eigen-directions identified by the FIM, DeFINO captures critical sensitivity information directly informed by observational data, significantly reducing computational expense. We validate DeFINO through synthetic experiments in the context of subsurface multi-phase fluid-flow, demonstrating improvements in gradient accuracy while maintaining robust forward predictions of underlying fluid dynamics. These results highlight DeFINO's potential to offer practical, scalable solutions for inversion problems in complex real-world scenarios, all at substantially reduced computational cost.</p></details> |  |
| **[Testing and benchmarking emerging supercomputers via the MFC flow solver](http://arxiv.org/abs/2509.13575v1)** | 2025-09-16 | <details><summary>Show</summary><p>Deploying new supercomputers requires testing and evaluation via application codes. Portable, user-friendly tools enable evaluation, and the Multicomponent Flow Code (MFC), a computational fluid dynamics (CFD) code, addresses this need. MFC is adorned with a toolchain that automates input generation, compilation, batch job submission, regression testing, and benchmarking. The toolchain design enables users to evaluate compiler-hardware combinations for correctness and performance with limited software engineering experience. As with other PDE solvers, wall time per spatially discretized grid point serves as a figure of merit. We present MFC benchmarking results for five generations of NVIDIA GPUs, three generations of AMD GPUs, and various CPU architectures, utilizing Intel, Cray, NVIDIA, AMD, and GNU compilers. These tests have revealed compiler bugs and regressions on recent machines such as Frontier and El Capitan. MFC has benchmarked approximately 50 compute devices and 5 flagship supercomputers.</p></details> | 9 pages, 3 figures |
| **[Curriculum Learning for Mesh-based simulations](http://arxiv.org/abs/2509.13138v1)** | 2025-09-16 | <details><summary>Show</summary><p>Graph neural networks (GNNs) have emerged as powerful surrogates for mesh-based computational fluid dynamics (CFD), but training them on high-resolution unstructured meshes with hundreds of thousands of nodes remains prohibitively expensive. We study a \emph{coarse-to-fine curriculum} that accelerates convergence by first training on very coarse meshes and then progressively introducing medium and high resolutions (up to \(3\times10^5\) nodes). Unlike multiscale GNN architectures, the model itself is unchanged; only the fidelity of the training data varies over time. We achieve comparable generalization accuracy while reducing total wall-clock time by up to 50\%. Furthermore, on datasets where our model lacks the capacity to learn the underlying physics, using curriculum learning enables it to break through plateaus.</p></details> |  |
| **[Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation](http://arxiv.org/abs/2509.13109v1)** | 2025-09-16 | <details><summary>Show</summary><p>This paper introduces a learning-based control framework for a soft robotic actuator system designed to modulate intracranial pressure (ICP) waveforms, which is essential for studying cerebrospinal fluid dynamics and pathological processes underlying neurological disorders. A two-layer framework is proposed to safely achieve a desired ICP waveform modulation. First, a model predictive controller (MPC) with a disturbance observer is used for offset-free tracking of the system's motor position reference trajectory under safety constraints. Second, to address the unknown nonlinear dependence of ICP on the motor position, we employ a Bayesian optimization (BO) algorithm used for online learning of a motor position reference trajectory that yields the desired ICP modulation. The framework is experimentally validated using a test bench with a brain phantom that replicates realistic ICP dynamics in vitro. Compared to a previously employed proportional-integral-derivative controller, the MPC reduces mean and maximum motor position reference tracking errors by 83 % and 73 %, respectively. In less than 20 iterations, the BO algorithm learns a motor position reference trajectory that yields an ICP waveform with the desired mean and amplitude.</p></details> |  |
| **[Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging](http://arxiv.org/abs/2509.13372v1)** | 2025-09-16 | <details><summary>Show</summary><p>Fontan palliation for univentricular congenital heart disease progresses to hemodynamic failure with complex flow patterns poorly characterized by conventional 2D imaging. Current assessment relies on fluoroscopic angiography, providing limited 3D geometric information essential for computational fluid dynamics (CFD) analysis and surgical planning. A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash (2.5B parameters) for systematic, iterative processing of fluoroscopic angiograms through transformer-based neural architecture. The pipeline encompasses medical image preprocessing, vascular segmentation, contrast enhancement, artifact removal, and virtual hemodynamic flow visualization within 2D projections. Final views were processed through Tencent's Hunyuan3D-2mini (384M parameters) for stereolithography file generation. The pipeline successfully generated geometrically optimized 2D projections from single-view angiograms after 16 processing steps using a custom web interface. Initial iterations contained hallucinated vascular features requiring iterative refinement to achieve anatomically faithful representations. Final projections demonstrated accurate preservation of complex Fontan geometry with enhanced contrast suitable for 3D conversion. AI-generated virtual flow visualization identified stagnation zones in central connections and flow patterns in branch arteries. Complete processing required under 15 minutes with second-level API response times. This approach demonstrates clinical feasibility of generating CFD-suitable geometries from routine angiographic data, enabling 3D generation and rapid virtual flow visualization for cursory insights prior to full CFD simulation. While requiring refinement cycles for accuracy, this establishes foundation for democratizing advanced geometric and hemodynamic analysis using readily available imaging data.</p></details> |  |
| **[Terradynamically streamlined shapes in animals and robots enhances traversability through densely cluttered terrain](http://arxiv.org/abs/1911.01797v2)** | 2025-09-15 | <details><summary>Show</summary><p>Many animals, modern aircraft, and underwater vehicles use streamlined body shapes that reduce fluid dynamic drag to achieve fast and effective locomotion in air and water. Similarly, numerous small terrestrial animals move through cluttered terrain where 3-D, multi-component obstacles like grass, shrubs, vines, and leaf litter resist motion, but it is unknown whether their body shape plays a major role in traversal. Few ground vehicles or terrestrial robots have used body shape to effectively traverse cluttered terrain. Here, we challenged forest-floor-dwelling discoid cockroaches possessing a thin, rounded body to traverse tall, narrowly spaced, vertical, grass-like compliant beams. Animals displayed high traversal performance (79 +/- 12% probability and 3.4 +/- 0.7 s time). Although we observed diverse traversal strategies, cockroaches primarily (48 +/- 9 % probability) used a novel roll maneuver, allowing them to rapidly traverse obstacle gaps narrower than half body width (2.0 +/- 0.5 s traversal time). Reduction of body roundness by addition of artificial shells nearly inhibited roll maneuvers and decreased traversal performance. Inspired by this discovery, we added a thin, rounded exoskeletal shell to a legged robot with a nearly cuboidal body, common to many existing terrestrial robots. Without adding sensory feedback or changing the open-loop control, the rounded shell enabled the robot to traverse beam obstacles with gaps narrower than shell width via body roll. Terradynamically streamlined shapes can reduce terrain resistance and enhance traversability by assisting effective body reorientation via distributed mechanical feedback. Our findings highlight the need to consider body shape to improve robot mobility in real-world terrain often filled with clutter, and to develop better locomotor-ground contact models to understand interaction with complex terrain.</p></details> |  |
| **[IGA-LBM: Isogeometric lattice Boltzmann method](http://arxiv.org/abs/2509.11427v1)** | 2025-09-14 | <details><summary>Show</summary><p>The lattice Boltzmann method has become a widely adopted approach in computational fluid dynamics, offering unique advantages in mesoscopic kinetic modeling, intrinsic parallelism, and simple treatment of boundary conditions. However, its conventional reliance on Cartesian grids fundamentally limits geometric fidelity in flows involving curved boundaries, introducing stair-step artifacts that propagate as spurious forces and boundary-layer inaccuracies. To address these challenges, we propose the isogeometric lattice Boltzmann method, which seamlessly integrates Isogeometric Analysis with LBM, leveraging the geometric precision of non-uniform rational B-Splines to construct body-fitted computational grids. Unlike conventional Cartesian-based LBM, the proposed approach eliminates stair-step boundary artifacts by providing sub-element geometric accuracy while maintaining the efficiency of LBM. Furthermore, the higher-order continuity of NURBS improves gradient resolution, reducing numerical diffusion in high-Reynold's-number flows. The parametric grid adaptation of IGA enables $h$-, $p$-, and $k$-refinement strategies, allowing for localized resolution enhancement in boundary layers and regions with high solution gradients. Additionally, the diffeomorphic mapping properties of IGA ensure intrinsic conservation, preserving advection invariants and suppressing numerical oscillations, leading to enhanced stability. Benchmark simulations on flows with curved and complex geometries demonstrate that IGA-LBM delivers significantly more accurate boundary-layer predictions and pressure/force estimates than standard Cartesian LBM, while preserving its computational efficiency and scalability. By combining geometric exactness with the algorithmic simplicity of LBM, IGA-LBM offers a practical route to high-fidelity simulations in engineering and scientific applications.</p></details> |  |
| **[WildSmoke: Ready-to-Use Dynamic 3D Smoke Assets from a Single Video in the Wild](http://arxiv.org/abs/2509.11114v1)** | 2025-09-14 | <details><summary>Show</summary><p>We propose a pipeline to extract and reconstruct dynamic 3D smoke assets from a single in-the-wild video, and further integrate interactive simulation for smoke design and editing. Recent developments in 3D vision have significantly improved reconstructing and rendering fluid dynamics, supporting realistic and temporally consistent view synthesis. However, current fluid reconstructions rely heavily on carefully controlled clean lab environments, whereas real-world videos captured in the wild are largely underexplored. We pinpoint three key challenges of reconstructing smoke in real-world videos and design targeted techniques, including smoke extraction with background removal, initialization of smoke particles and camera poses, and inferring multi-view videos. Our method not only outperforms previous reconstruction and generation methods with high-quality smoke reconstructions (+2.22 average PSNR on wild videos), but also enables diverse and realistic editing of fluid dynamics by simulating our smoke assets. We provide our models, data, and 4D smoke assets at [https://autumnyq.github.io/WildSmoke](https://autumnyq.github.io/WildSmoke).</p></details> |  |
| **[Deep Reinforcement Learning for Active Flow Control around a Three-Dimensional Flow-Separated Wing at Re = 1,000](http://arxiv.org/abs/2509.10195v1)** | 2025-09-12 | <details><summary>Show</summary><p>This study explores the use of deep reinforcement learning (DRL) for active flow control (AFC) to reduce flow separation on wings at high angles of attack. Concretely, here the DRL agent controls the flow over the three-dimensional NACA0012 wing section at the Reynolds number Re = 1,000 and angle of attack AoA = 20 degrees, autonomously identifying optimal control actions through real-time flow data and a reward function focused on improving aerodynamic performance. The framework integrates the GPU-accelerated computational fluid dynamics (CFD) solver SOD2D with the TF-Agents DRL library via a Redis in-memory database, enabling rapid training. This work builds on previous DRL flow-control studies, demonstrating DRL potential to address complex aerodynamic challenges and push the boundaries of traditional AFC methods.</p></details> |  |
| **[An Integrated Open Source Software System for the Generation and Analysis of Subject-Specific Blood Flow Simulation Ensembles](http://arxiv.org/abs/2509.09392v1)** | 2025-09-11 | <details><summary>Show</summary><p>Background and Objective: Hemodynamic analysis of blood flow through arteries and veins is critical for diagnosing cardiovascular diseases, such as aneurysms and stenoses, and for investigating cardiovascular parameters, such as turbulence and wall shear stress. For subject-specific analyses, the anatomy and blood flow of the subject can be captured non-invasively using structural and 4D Magnetic Resonance Imaging (MRI). Computational Fluid Dynamics (CFD), on the other hand, can be used to generate blood flow simulations by solving the Navier-Stokes equations. To generate and analyze subject-specific blood flow simulations, MRI and CFD have to be brought together. Methods: We present an interactive, customizable, and user-oriented visual analysis tool that assists researchers in both medicine and numerical analysis. Our open-source tool is applicable to domains such as CFD and MRI, and it facilitates the analysis of simulation results and medical data, especially in hemodynamic studies. It enables the creation of simulation ensembles with a high variety of parameters. Furthermore, it allows for the visual and analytical examination of simulations and measurements through 2D embeddings of the similarity space. Results: To demonstrate the effectiveness of our tool, we applied it to three real-world use cases, showcasing its ability to configure simulation ensembles and analyse blood flow dynamics. We evaluated our example cases together with MRI and CFD experts to further enhance features and increase the usability. Conclusions: By combining the strengths of both CFD and MRI, our tool provides a more comprehensive understanding of hemodynamic parameters, facilitating more accurate analysis of hemodynamic biomarkers.</p></details> | <details><summary>21 pa...</summary><p>21 pages, 7 figures, 2 tables</p></details> |
| **[Learning Fluid-Structure Interaction Dynamics with Physics-Informed Neural Networks and Immersed Boundary Methods](http://arxiv.org/abs/2505.18565v4)** | 2025-09-10 | <details><summary>Show</summary><p>Physics-informed neural networks (PINNs) have emerged as a promising approach for solving complex fluid dynamics problems, yet their application to fluid-structure interaction (FSI) problems with moving boundaries remains largely unexplored. This work addresses the critical challenge of modeling FSI systems with deformable interfaces, where traditional unified PINN architectures struggle to capture the distinct physics governing fluid and structural domains simultaneously. We present an innovative Eulerian-Lagrangian PINN architecture that integrates immersed boundary method (IBM) principles to solve FSI problems with moving boundary conditions. Our approach fundamentally departs from conventional unified architectures by introducing domain-specific neural networks: an Eulerian network for fluid dynamics and a Lagrangian network for structural interfaces, coupled through physics-based constraints. Additionally, we incorporate learnable B-spline activation functions with SiLU to capture both localized high-gradient features near interfaces and global flow patterns. Empirical studies on a 2D cavity flow problem involving a moving solid structure show that while baseline unified PINNs achieve reasonable velocity predictions, they suffer from substantial pressure errors (12.9%) in structural regions. Our Eulerian-Lagrangian architecture with learnable activations (EL-L) achieves better performance across all metrics, improving accuracy by 24.1-91.4% and particularly reducing pressure errors from 12.9% to 2.39%. These results demonstrate that domain decomposition aligned with physical principles, combined with locality-aware activation functions, is essential for accurate FSI modeling within the PINN framework.</p></details> |  |
| **[Interpretable Physics Reasoning and Performance Taxonomy in Vision-Language Models](http://arxiv.org/abs/2509.08270v1)** | 2025-09-10 | <details><summary>Show</summary><p>As Vision-Language Models (VLMs) grow in sophistication, their ability to perform reasoning is coming under increasing supervision. While they excel at many tasks, their grasp of fundamental scientific principles, such as physics, remains an underexplored frontier. To reflect the advancements in these capabilities, we introduce a novel and accessible framework designed to rigorously evaluate VLMs on their understanding of 2D physics. Our framework features a pragmatic scenario generator that creates a diverse testbed of over 400 problems across four core domains: Projectile Motion, Collision Dynamics, Mechanics, and Fluid Dynamics. Through comprehensive evaluation of four state-of-the-art VLMs, we demonstrate a strong correlation between model scale and reasoning ability, with our top-performing model, Qwen2.5-VL-7B, achieving an overall score of 0.815. We find that while models excel at formulaic problems, they struggle significantly with domains requiring abstract spatial reasoning. By designing this framework, we aim to democratize the study of scientific reasoning in VLMs and foster deeper insights into their capabilities and limitations.</p></details> |  |
| **[Tensor-Train Operator Inference](http://arxiv.org/abs/2509.08071v1)** | 2025-09-09 | <details><summary>Show</summary><p>In this study, we present a tensor--train framework for nonintrusive operator inference aimed at learning discrete operators and using them to predict solutions of physical governing equations. Our framework comprises three approaches: full--order tensor--train operator inference, full--order quantized tensor--train operator inference, and reduced--order tensor--train operator inference. In each case, snapshot data is represented in tensor--train format--either through compression or cross interpolation--enabling the efficient handling of extremely large datasets with significantly reduced computational effort compared to standard methods. The effectiveness of each approach is demonstrated through numerical experiments related to Computational Fluid Dynamics and benchmarked against the standard reduced--order operator inference method, highlighting the advantages of the tensor--train representations in both accuracy and scalability.</p></details> | AIAA SciTech 2026 |
| **[Mixed-precision numerics in scientific applications: survey and perspectives](http://arxiv.org/abs/2412.19322v3)** | 2025-09-08 | <details><summary>Show</summary><p>The explosive demand for artificial intelligence (AI) workloads has led to a significant increase in silicon area dedicated to lower-precision computations on recent high-performance computing hardware designs. However, mixed-precision capabilities, which can achieve performance improvements of 8x compared to double-precision in extreme compute-intensive workloads, remain largely untapped in most scientific applications. A growing number of efforts have shown that mixed-precision algorithmic innovations can deliver superior performance without sacrificing accuracy. These developments should prompt computational scientists to seriously consider whether their scientific modeling and simulation applications could benefit from the acceleration offered by new hardware and mixed-precision algorithms. In this survey, we (1) review progress across diverse scientific domains -- including fluid dynamics, weather and climate, quantum chemistry, and computational genomics -- that have begun adopting mixed-precision strategies; (2) examine state-of-the-art algorithmic techniques such as iterative refinement, splitting and emulation schemes, and adaptive precision solvers; (3) assess their implications for accuracy, performance, and resource utilization; and (4) survey the emerging software ecosystem that enables mixed-precision methods at scale. We conclude with perspectives and recommendations on cross-cutting opportunities, domain-specific challenges, and the role of co-design between application scientists, numerical analysts and computer scientists. Collectively, this survey underscores that mixed-precision numerics can reshape computational science by aligning algorithms with the evolving landscape of hardware capabilities.</p></details> | <details><summary>Submi...</summary><p>Submitted to Journal of Supercomputing</p></details> |
| **[ChatCFD: An LLM-Driven Agent for End-to-End CFD Automation with Domain-Specific Structured Reasoning](http://arxiv.org/abs/2506.02019v2)** | 2025-09-08 | <details><summary>Show</summary><p>Computational Fluid Dynamics (CFD) is essential for advancing scientific and engineering fields but is hindered by operational complexity, high expertise requirements, and limited accessibility. This paper introduces ChatCFD, an automated agent system for OpenFOAM simulations that processes multi-modal inputs (e.g., research papers, meshes) via an interactive interface, leveraging DeepSeek-R1 and DeepSeek-V3 large language models, a multi-agent architecture, and OpenFOAM knowledge. Its four-stage pipeline (Knowledge Base Construction, User Input Processing, Case File Generation, and Execution and Error Reflection) enables iterative trial-reflection-refinement for intricate setups, supporting diverse physical models and external meshes. Validation on 205 benchmark tutorial cases, 110 perturbed variants, and 2 literature-derived cases shows ChatCFD's 82.1 percent operational success rate on basic cases, outperforming MetaOpenFOAM (6.2 percent) and Foam-Agent (42.3 percent), and 60-80 percent on literature-derived complex cases. Turbulence model studies show a 40 percent success rate for common models versus 10 percent for rare ones like RNG k-epsilon. Physics coupling analyses reveal higher resource demands for multi-physics-coupled cases, while LLM bias toward simpler setups introduces persistent errors, such as dimensional inconsistency. Ablation studies highlight the efficacy of RAG-based modules and reflection mechanisms. By automating hypothesis testing and parameter exploration, ChatCFD accelerates scientific discovery in fluid mechanics and engineering, addressing LLM limitations through structured design and showing strong potential as a modular component in MCP-based agent networks for collaborative multi-agent systems, paving the way for scalable AI-driven CFD innovation. The code for ChatCFD is available at https://github.com/ConMoo/ChatCFD.</p></details> | 19 pages, 8 figures |
| **[A novel biomass fluidized bed gasification model coupled with machine learning and CFD simulation](http://arxiv.org/abs/2509.06056v1)** | 2025-09-07 | <details><summary>Show</summary><p>A coupling model of biomass fluidized bed gasification based on machine learning and computational fluid dynamics is proposed to improve the prediction accuracy and computational efficiency of complex thermochemical reaction process. By constructing a high-quality data set based on experimental data and high fidelity simulation results, the agent model used to describe the characteristics of reaction kinetics was trained and embedded into the computational fluid dynamics (CFD) framework to realize the real-time update of reaction rate and composition evolution.</p></details> |  |
| **[Multi-Stage Graph Neural Networks for Data-Driven Prediction of Natural Convection in Enclosed Cavities](http://arxiv.org/abs/2509.06041v1)** | 2025-09-07 | <details><summary>Show</summary><p>Buoyancy-driven heat transfer in closed cavities serves as a canonical testbed for thermal design High-fidelity CFD modelling yields accurate thermal field solutions, yet its reliance on expert-crafted physics models, fine meshes, and intensive computation limits rapid iteration. Recent developments in data-driven modeling, especially Graph Neural Networks (GNNs), offer new alternatives for learning thermal-fluid behavior directly from simulation data, particularly on irregular mesh structures. However, conventional GNNs often struggle to capture long-range dependencies in high-resolution graph structures. To overcome this limitation, we propose a novel multi-stage GNN architecture that leverages hierarchical pooling and unpooling operations to progressively model global-to-local interactions across multiple spatial scales. We evaluate the proposed model on our newly developed CFD dataset simulating natural convection within a rectangular cavities with varying aspect ratios where the bottom wall is isothermal hot, the top wall is isothermal cold, and the two vertical walls are adiabatic. Experimental results demonstrate that the proposed model achieves higher predictive accuracy, improved training efficiency, and reduced long-term error accumulation compared to state-of-the-art (SOTA) GNN baselines. These findings underscore the potential of the proposed multi-stage GNN approach for modeling complex heat transfer in mesh-based fluid dynamics simulations.</p></details> |  |
| **[SPINN: An Optimal Self-Supervised Physics-Informed Neural Network Framework](http://arxiv.org/abs/2509.05886v1)** | 2025-09-07 | <details><summary>Show</summary><p>A surrogate model is developed to predict the convective heat transfer coefficient of liquid sodium (Na) flow within rectangular miniature heat sinks. Initially, kernel-based machine learning techniques and shallow neural network are applied to a dataset with 87 Nusselt numbers for liquid sodium in rectangular miniature heat sinks. Subsequently, a self-supervised physics-informed neural network and transfer learning approach are used to increase the estimation performance. In the self-supervised physics-informed neural network, an additional layer determines the weight the of physics in the loss function to balance data and physics based on their uncertainty for a better estimation. For transfer learning, a shallow neural network trained on water is adapted for use with Na. Validation results show that the self-supervised physics-informed neural network successfully estimate the heat transfer rates of Na with an error margin of approximately +8%. Using only physics for regression, the error remains between 5% to 10%. Other machine learning methods specify the prediction mostly within +8%. High-fidelity modeling of turbulent forced convection of liquid metals using computational fluid dynamics (CFD) is both time-consuming and computationally expensive. Therefore, machine learning based models offer a powerful alternative tool for the design and optimization of liquid-metal-cooled miniature heat sinks.</p></details> |  |
| **[Energy Transfer Dynamics Generated by Non-Axisymmetric Tornado-Type Flows](http://arxiv.org/abs/2509.05546v1)** | 2025-09-06 | <details><summary>Show</summary><p>The energy cascade in turbulence, first statistically described by Richardson (1922) and Kolmogorov (1941), lacked connection to the underlying fluid dynamics. Recent numerical studies of Goto et al. (2017) and Yoneda et al. (2022) revealed scale-local energy transfer via vortex stretching but remained within spatial statistics. This study aims to uncover the time-dependent elementary process behind the energy cascade by constructing a tornado-type flow in a non-axisymmetric curved cylindrical domain. Our approach reveals specific vortex dynamics responsible for energy transfer, offering new insight into the physical mechanisms of turbulence.</p></details> | 15 pages, 15 figures |
| **[TripOptimizer: Generative 3D Shape Optimization and Drag Prediction using Triplane VAE Networks](http://arxiv.org/abs/2509.12224v1)** | 2025-09-05 | <details><summary>Show</summary><p>The computational cost of traditional Computational Fluid Dynamics-based Aerodynamic Shape Optimization severely restricts design space exploration. This paper introduces TripOptimizer, a fully differentiable deep learning framework for rapid aerodynamic analysis and shape optimization directly from vehicle point cloud data. TripOptimizer employs a Variational Autoencoder featuring a triplane-based implicit neural representation for high-fidelity 3D geometry reconstruction and a drag coefficient prediction head. Trained on DrivAerNet++, a large-scale dataset of 8,000 unique vehicle geometries with corresponding drag coefficients computed via Reynolds-Averaged Navier-Stokes simulations, the model learns a latent representation that encodes aerodynamically salient geometric features. We propose an optimization strategy that modifies a subset of the encoder parameters to steer an initial geometry towards a target drag value, and demonstrate its efficacy in case studies where optimized designs achieved drag coefficient reductions up to 11.8\%. These results were subsequently validated by using independent, high-fidelity Computational Fluid Dynamics simulations with more than 150 million cells. A key advantage of the implicit representation is its inherent robustness to geometric imperfections, enabling optimization of non-watertight meshes, a significant challenge for traditional adjoint-based methods. The framework enables a more agile Aerodynamic Shape Optimization workflow, reducing reliance on computationally intensive CFD simulations, especially during early design stages.</p></details> |  |

## Model Reduction
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[A space-decoupling framework for optimization on bounded-rank matrices with orthogonally invariant constraints](http://arxiv.org/abs/2501.13830v2)** | 2025-09-30 | <details><summary>Show</summary><p>Imposing additional constraints on low-rank optimization has garnered growing interest. However, the geometry of coupled constraints hampers the well-developed low-rank structure and makes the problem intricate. To this end, we propose a space-decoupling framework for optimization on bounded-rank matrices with orthogonally invariant constraints. The "space-decoupling" is reflected in several ways. We show that the tangent cone of coupled constraints is the intersection of tangent cones of each constraint. Moreover, we decouple the intertwined bounded-rank and orthogonally invariant constraints into two spaces, leading to optimization on a smooth manifold. Implementing Riemannian algorithms on this manifold is painless as long as the geometry of additional constraints is known. In addition, we unveil the equivalence between the reformulated problem and the original problem. Numerical experiments on real-world applications -- spherical data fitting, graph similarity measuring, low-rank SDP, model reduction of Markov processes, reinforcement learning, and deep learning -- validate the superiority of the proposed framework.</p></details> | <details><summary>50 pa...</summary><p>50 pages, 12 figures, 6 tables</p></details> |
| **[Information theory for data-driven model reduction in physics and biology](http://arxiv.org/abs/2312.06608v3)** | 2025-09-28 | <details><summary>Show</summary><p>Model reduction is the construction of simple yet predictive descriptions of the dynamics of many-body systems in terms of a few relevant variables. A prerequisite to model reduction is the identification of these variables, a task for which no general method exists. Here, we develop an approach to identify relevant variables, defined as those most predictive of the future, using the so-called information bottleneck. We elucidate analytically the relation between these relevant variables and the eigenfunctions of the transfer operator describing the dynamics. In the limit of high compression, the relevant variables are directly determined by the slowest-decaying eigenfunctions. Our results provide a firm foundation to interpret deep learning tools that automatically identify reduced variables. Combined with equation learning methods this procedure yields the hidden dynamical rules governing the system's evolution in a data-driven manner. We illustrate how these tools work in diverse settings including model chaotic and quasiperiodic systems in which we also learn the underlying dynamical equations, uncurated satellite recordings of atmospheric fluid flows, and experimental videos of cyanobacteria colonies in which we discover an emergent synchronization order parameter.</p></details> | 62 pages, 26 figures |
| **[Model reduction of parametric ordinary differential equations via autoencoders: structure-preserving latent dynamics and convergence analysis](http://arxiv.org/abs/2509.21280v1)** | 2025-09-25 | <details><summary>Show</summary><p>We propose a reduced-order modeling approach for nonlinear, parameter-dependent ordinary differential equations (ODE). Dimensionality reduction is achieved using nonlinear maps represented by autoencoders. The resulting low-dimensional ODE is then solved using standard integration in time schemes, and the high-dimensional solution is reconstructed from the low-dimensional one. We investigate the applicability of neural networks for constructing effective autoencoders with the property of reconstructing the input manifold with null representation error. We study the convergence of the reduced-order model to the high-fidelity one. Numerical experiments show the robustness and accuracy of our approach, highlighting its potential to accelerate complex dynamical simulations without sacrificing accuracy. Moreover, we examine how the reduction influences the stability properties of the reconstructed high-dimensional solution.</p></details> |  |
| **[Latent Twins](http://arxiv.org/abs/2509.20615v1)** | 2025-09-24 | <details><summary>Show</summary><p>Over the past decade, scientific machine learning has transformed the development of mathematical and computational frameworks for analyzing, modeling, and predicting complex systems. From inverse problems to numerical PDEs, dynamical systems, and model reduction, these advances have pushed the boundaries of what can be simulated. Yet they have often progressed in parallel, with representation learning and algorithmic solution methods evolving largely as separate pipelines. With \emph{Latent Twins}, we propose a unifying mathematical framework that creates a hidden surrogate in latent space for the underlying equations. Whereas digital twins mirror physical systems in the digital world, Latent Twins mirror mathematical systems in a learned latent space governed by operators. Through this lens, classical modeling, inversion, model reduction, and operator approximation all emerge as special cases of a single principle. We establish the fundamental approximation properties of Latent Twins for both ODEs and PDEs and demonstrate the framework across three representative settings: (i) canonical ODEs, capturing diverse dynamical regimes; (ii) a PDE benchmark using the shallow-water equations, contrasting Latent Twin simulations with DeepONet and forecasts with a 4D-Var baseline; and (iii) a challenging real-data geopotential reanalysis dataset, reconstructing and forecasting from sparse, noisy observations. Latent Twins provide a compact, interpretable surrogate for solution operators that evaluate across arbitrary time gaps in a single-shot, while remaining compatible with scientific pipelines such as assimilation, control, and uncertainty quantification. Looking forward, this framework offers scalable, theory-grounded surrogates that bridge data-driven representation learning and classical scientific modeling across disciplines.</p></details> | <details><summary>38 pa...</summary><p>38 pages, 22 figures, 1 table</p></details> |
| **[Robust, positive and exact model reduction via monotone matrices](http://arxiv.org/abs/2406.11696v4)** | 2025-09-17 | <details><summary>Show</summary><p>This work focuses on the problem of exact model reduction of positive linear systems, by leveraging minimal realization theory. While determining the existence of a positive reachable realization remains in general an open problem, we are able to fully characterize the cases in which the new model is obtained with non-negative reduction matrices, and hence positivity of the reduced model is robust with respect to small perturbations of the original system. The characterization is obtained by specializing monotone matrix theory to positive matrices. In addition, we provide a systematic method to construct positive reductions also when minimal ones are not available, by exploiting algebraic techniques.</p></details> |  |
| **[Finite Sample Analysis of Open-loop Subspace Identification Methods](http://arxiv.org/abs/2501.16639v2)** | 2025-09-17 | <details><summary>Show</summary><p>Subspace identification methods (SIMs) are known for their simple parameterization for MIMO systems and robust numerical properties. However, a comprehensive statistical analysis of SIMs remains an open problem. Following a three-step procedure generally used in SIMs, this work presents a finite sample analysis for open-loop SIMs. In Step 1 we begin with a parsimonious SIM. Leveraging a recent analysis of an individual ARX model, we obtain a union error bound for a Hankel-like matrix constructed from a bank of ARX models. Step 2 involves model reduction via weighted singular value decomposition (SVD), where we use robustness results for SVD to obtain error bounds on extended controllability and observability matrices, respectively. The final Step 3 focuses on deriving error bounds for system matrices, where two different realization algorithms, the MOESP type and the CVA type, are studied. Our results not only agree with classical asymptotic results, but also show how much data is needed to guarantee a desired error bound with high probability. The proposed method generalizes related finite sample analyses and applies broadly to many variants of SIMs.</p></details> |  |
| **[Quantum model reduction for continuous-time quantum filters](http://arxiv.org/abs/2501.13885v3)** | 2025-09-16 | <details><summary>Show</summary><p>The use of quantum stochastic models is widespread in dynamical reduction, simulation of open systems, feedback control and adaptive estimation. In many applications only part of the information contained in the filter's state is actually needed to reconstruct the target observable quantities; thus, filters of smaller dimensions could be in principle implemented to perform the same task.In this work, we propose a systematic method to find, when possible, reduced-order quantum filters that are capable of exactly reproducing the evolution of expectation values of interest. In contrast with existing reduction techniques, the reduced model we obtain is exact and in the form of a Belavkin filtering equation, ensuring physical interpretability.This is attained by leveraging tools from the theory of both minimal realization and non-commutative conditional expectations. The proposed procedure is tested on prototypical examples, laying the groundwork for applications in quantum trajectory simulation and quantum feedback control.</p></details> |  |
| **[Adapting Projection-Based Reduced-Order Models using Projected Gaussian Process](http://arxiv.org/abs/2410.14090v2)** | 2025-09-14 | <details><summary>Show</summary><p>Projection-based model reduction is among the most widely adopted methods for constructing parametric Reduced-Order Models (ROM). Utilizing the snapshot data from solving full-order governing equations, the Proper Orthogonal Decomposition (POD) computes the optimal basis modes that represent the data, and a ROM can be constructed in the low-dimensional vector subspace spanned by the POD basis. For parametric governing equations, a potential challenge arises when there is a need to update the POD basis to adapt ROM that accurately capture the variation of a system's behavior over its parameter space (in design, control, uncertainty quantification, digital twins applications, etc.). In this paper, we propose a Projected Gaussian Process (pGP) and formulate the problem of adapting the POD basis as a supervised statistical learning problem, for which the goal is to learn a mapping from the parameter space to the Grassmann manifold that contains the optimal subspaces. A mapping is firstly established between the Euclidean space and the horizontal space of an orthogonal matrix that spans a reference subspace in the Grassmann manifold. A second mapping from the horizontal space to the Grassmann manifold is established through the Exponential/Logarithm maps between the manifold and its tangent space. Finally, given a new parameter, the conditional distribution of a vector can be found in the Euclidean space using the Gaussian Process (GP) regression, and such a distribution is then projected to the Grassmann manifold that enables us to predict the optimal subspace for the new parameter. As a statistical learning approach, the proposed pGP allows us to optimally estimate (or tune) the model parameters from data and quantify the statistical uncertainty associated with the prediction. The advantages of the proposed pGP are demonstrated by numerical experiments.</p></details> |  |
| **[Deep Global Model Reduction Learning in Porous Media Flow Simulation](http://arxiv.org/abs/1807.09335v2)** | 2025-09-11 | <details><summary>Show</summary><p>In this paper, we combine deep learning concepts and some proper orthogonal decomposition (POD) model reduction methods for predicting flow in heterogeneous porous media. Nonlinear flow dynamics is studied, where the dynamics is regarded as a multi-layer network. The solution at the current time step is regarded as a multi-layer network of the solution at the initial time and input parameters. As for input, we consider various sources, which include source terms (well rates), permeability fields, and initial conditions. We consider the flow dynamics, where the solution is known at some locations and the data is integrated to the flow dynamics by modifying the reduced-order model. This approach allows modifying the reduced-order formulation of the problem. Because of the small problem size, limited observed data can be handled. We consider enriching the observed data using the computational data in deep learning networks. The basis functions of the global reduced order model are selected such that the degrees of freedom represent the solution at observation points. This way, we can avoid learning basis functions, which can also be done using neural networks. We present numerical results, where we consider channelized permeability fields, where the network is constructed for various channel configurations. Our numerical results show that one can achieve a good approximation using forward feed maps based on multi-layer networks.</p></details> |  |
| **[Efficient High-Order Participation Factor Computation via Batch-Structured Tensor Contraction](http://arxiv.org/abs/2509.08968v1)** | 2025-09-10 | <details><summary>Show</summary><p>Participation factors (PFs) quantify the interaction between system modes and state variables, and they play a crucial role in various applications such as modal analysis, model reduction, and control design. With increasing system complexity, especially due to power electronic devices and renewable integration, the need for scalable and high-order nonlinear PF (NPF) computation has become more critical. This paper presents an efficient tensor-based method for calculating NPFs up to an arbitrary order. Traditional computation of PFs directly from normal form theory is computationally expensive -- even for second-order PFs -- and becomes infeasible for higher orders due to memory constraints. To address this, a tensor contraction-based approach is introduced that enables the calculation of high-order PFs using a batching strategy. The batch sizes are dynamically determined based on the available computational resources, allowing scalable and memory-efficient computation.</p></details> |  |
| **[Hybrid Physics-Data Enrichments to Represent Uncertainty in Reduced Gas-Surface Chemistry Models for Hypersonic Flight](http://arxiv.org/abs/2509.08137v1)** | 2025-09-09 | <details><summary>Show</summary><p>During hypersonic flight, air reacts with a planetary re-entry vehicle's thermal protection system (TPS), creating reaction products that deplete the TPS. Reliable assessment of TPS performance depends on accurate ablation models. New finite-rate gas-surface chemistry models are advancing state-of-the-art in TPS ablation modeling, but model reductions that omit chemical species and reactions may be necessary in some cases for computational tractability. This work develops hybrid physics-based and data-driven enrichments to improve the predictive capability and quantify uncertainties in such low-fidelity models while maintaining computational tractability. We focus on discrepancies in predicted carbon monoxide production that arise because the low-fidelity model tracks only a subset of reactions. To address this, we embed targeted enrichments into the low-fidelity model to capture the influence of omitted reactions. Numerical results show that the hybrid enrichments significantly improve predictive accuracy while requiring the addition of only three reactions.</p></details> |  |
| **[Parameter Robustness in Data-Driven Estimation of Dynamical Systems](http://arxiv.org/abs/2509.06534v1)** | 2025-09-08 | <details><summary>Show</summary><p>We study the robustness of system estimation to parametric perturbations in system dynamics and initial conditions. We define the problem of sensitivity-based parametric uncertainty quantification in dynamical system estimation. The main contribution of this paper is the development of a novel robustness metric for estimation of parametrized linear dynamical systems with and without control actions. For the computation of this metric, we delineate the uncertainty contributions arising from control actions, system dynamics, and initial conditions. Furthermore, to validate our theoretical findings, we establish connections between these new results and the existing literature on the robustness of model reduction. This work provides guidance for selecting estimation methods based on tolerable levels of parametric uncertainty and paves the way for new cost functions in data-driven estimation that reward sensitivity to a desired subset of parameters while penalizing others.</p></details> | <details><summary>Submi...</summary><p>Submitted for publication in the IEEE Conference on Decision and Control (CDC) 2025</p></details> |
| **[Transmission Conditions for the Non-Overlapping Schwarz Coupling of Full Order and Operator Inference Models](http://arxiv.org/abs/2509.12228v1)** | 2025-09-06 | <details><summary>Show</summary><p>This work investigates transmission conditions for the domain decomposition-based coupling of subdomain-local models using the non-overlapping Schwarz alternating method (NO-SAM). Building on prior efforts involving overlapping SAM (O-SAM), we formulate and assess two NO-SAM variants, based on alternating Dirichlet-Neumann and Robin-Robin transmission conditions. For the subdomain-local models, we consider a mix of full order models (FOMs) and non-intrusive reduced order models (ROMs) constructed via an emerging model reduction technique known as operator inference (OpInf). Of particular novelty is the first application of NO-SAM to couple non-intrusive OpInf ROMs with each other, and with FOMs. Numerical studies on a one-dimensional linear elastic wave propagation benchmark problem demonstrate that transmission condition choice and parameter tuning significantly impact convergence rate, accuracy, and stability. Robin-Robin coupling often yields faster convergence than alternating Dirichlet-Neumann, though improper parameter selection can induce spurious oscillations at subdomain interfaces. For FOM-OpInf and OpInf-OpInf couplings, sufficient modal content in the ROM basis improves accuracy and mitigates instability, in some cases outperforming the coupled FOM-FOM reference solutions in both accuracy and efficiency. These findings highlight NO-SAM's potential for enabling flexible, non-intrusive, and efficient multi-model coupling across independently meshed subdomains, while emphasizing the need for careful interface condition design in higher-dimensional and predictive settings.</p></details> |  |
| **[Fractional differential equations: non-constant coefficients, simulation and model reduction](http://arxiv.org/abs/2509.02465v1)** | 2025-09-02 | <details><summary>Show</summary><p>We consider boundary value problems with Riemann-Liouville fractional derivatives of order $s\in (1, 2)$ with non-constant diffusion and reaction coefficients. A variational formulation is derived and analyzed leading to the well-posedness of the continuous problem and its Finite Element discretization. Then, the Reduced Basis Method through a greedy algorithm for parametric diffusion and reaction coefficients is analyzed. Its convergence properties, and in particular the decay of the Kolmogorov $n$-width, are seen to depend on the fractional order $s$. Finally, numerical results confirming our findings are presented.</p></details> |  |
| **[A locking free multiscale method for linear elasticity in stress-displacement formulation with high contrast coefficients](http://arxiv.org/abs/2504.18054v2)** | 2025-09-01 | <details><summary>Show</summary><p>Achieving strongly symmetric stress approximations for linear elasticity problems in high-contrast media poses a significant computational challenge. Conventional methods often struggle with prohibitively high computational costs due to excessive degrees of freedom, limiting their practical applicability. To overcome this challenge, we introduce an efficient multiscale model reduction method and a computationally inexpensive coarse-grid simulation technique for linear elasticity equations in highly heterogeneous, high-contrast media. We first utilize a stable stress-displacement mixed finite element method to discretize the linear elasticity problem and then present the construction of multiscale basis functions for the displacement and the stress. The mixed formulation offers several advantages such as direct stress computation without post-processing, local momentum conservation (ensuring physical consistency), and robustness against locking effects, even for nearly incompressible materials. Theoretical analysis confirms that our method is inf-sup stable and locking-free, with first-order convergence relative to the coarse mesh size. Notably, the convergence remains independent of contrast ratios as enlarging oversampling regions. Numerical experiments validate the method's effectiveness, demonstrating its superior performance even under extreme contrast conditions.</p></details> |  |
| **[Machine-precision energy conservative quadrature hyperreduction of Lagrangian hydrodynamics](http://arxiv.org/abs/2508.21279v1)** | 2025-08-29 | <details><summary>Show</summary><p>We present an energy conservative, quadrature based model reduction framework for the compressible Euler equations of Lagrangian hydrodynamics. Building on a high order finite element discretization of the governing equations, we develop a projection based reduced model using data driven reduced basis functions and hyperreduction via the empirical quadrature procedure (EQP). We introduce a strongly energy conservative variant of EQP that enforces exact discrete total energy conservation during the hyperreduction process. Numerical experiments for four benchmark problems -- Sedov blast, Gresho vortex, triple point and Taylor-Green vortex -- demonstrate that the numerical implementation of our proposed method conserves total energy to near machine precision while maintaining accuracy comparable to the basic EQP formulation. These results establish the energy conservative EQP (CEQP) method as an effective structure preserving hyperreduction strategy for the reduced simulation of nonlinear Lagrangian hydrodynamics.</p></details> | 24 pages, 1 figure |
| **[Possible Principles for Aligned Structure Learning Agents](http://arxiv.org/abs/2410.00258v3)** | 2025-08-27 | <details><summary>Show</summary><p>This paper offers a roadmap for the development of scalable aligned artificial intelligence (AI) from first principle descriptions of natural intelligence. In brief, a possible path toward scalable aligned AI rests upon enabling artificial agents to learn a good model of the world that includes a good model of our preferences. For this, the main objective is creating agents that learn to represent the world and other agents' world models; a problem that falls under structure learning (a.k.a. causal representation learning or model discovery). We expose the structure learning and alignment problems with this goal in mind, as well as principles to guide us forward, synthesizing various ideas across mathematics, statistics, and cognitive science. 1) We discuss the essential role of core knowledge, information geometry and model reduction in structure learning, and suggest core structural modules to learn a wide range of naturalistic worlds. 2) We outline a way toward aligned agents through structure learning and theory of mind. As an illustrative example, we mathematically sketch Asimov's Laws of Robotics, which prescribe agents to act cautiously to minimize the ill-being of other agents. We supplement this example by proposing refined approaches to alignment. These observations may guide the development of artificial intelligence in helping to scale existing -- or design new -- aligned structure learning systems.</p></details> | <details><summary>24 pa...</summary><p>24 pages of content, 33 with references; accepted version</p></details> |
| **[Multi-field decomposed hyper-reduced order modeling of damage-plasticity simulations](http://arxiv.org/abs/2508.19957v1)** | 2025-08-27 | <details><summary>Show</summary><p>This paper presents a multi-field decomposed approach for hyper-reduced order modeling to overcome the limitations of traditional model reduction techniques for gradient-extended damage-plasticity simulations. The discrete empirical interpolation method (DEIM) and the energy-conserving sampling and weighting method (ECSW) are extended to account for the multi-field nature of the problem. Both methods yield stable reduced order simulations, while significantly reducing the computational cost compared to full-order simulations. Two numerical examples are presented to demonstrate the performance and limitations of the proposed approaches. The decomposed ECSW method has overall higher accuracy and lower computational cost than the decomposed DEIM method.</p></details> |  |
| **[Constraint Matters: Multi-Modal Representation for Reducing Mixed-Integer Linear programming](http://arxiv.org/abs/2508.18742v1)** | 2025-08-26 | <details><summary>Show</summary><p>Model reduction, which aims to learn a simpler model of the original mixed integer linear programming (MILP), can solve large-scale MILP problems much faster. Most existing model reduction methods are based on variable reduction, which predicts a solution value for a subset of variables. From a dual perspective, constraint reduction that transforms a subset of inequality constraints into equalities can also reduce the complexity of MILP, but has been largely ignored. Therefore, this paper proposes a novel constraint-based model reduction approach for the MILP. Constraint-based MILP reduction has two challenges: 1) which inequality constraints are critical such that reducing them can accelerate MILP solving while preserving feasibility, and 2) how to predict these critical constraints efficiently. To identify critical constraints, we first label these tight-constraints at the optimal solution as potential critical constraints and design a heuristic rule to select a subset of critical tight-constraints. To learn the critical tight-constraints, we propose a multi-modal representation technique that leverages information from both instance-level and abstract-level MILP formulations. The experimental results show that, compared to the state-of-the-art methods, our method improves the quality of the solution by over 50\% and reduces the computation time by 17.47\%.</p></details> |  |
| **[Generalizations of data-driven balancing: What to sample for different balancing-based reduced models](http://arxiv.org/abs/2312.12561v2)** | 2025-08-25 | <details><summary>Show</summary><p>The quadrature-based balanced truncation (QuadBT) framework of arXiv:2104.01006 is a non-intrusive reformulation of balanced truncation (BT), a classical projection-based model-order reduction technique for linear systems. QuadBT is non-intrusive in the sense that it builds approximate balanced truncation reduced-order models entirely from system response data, e.g., transfer function measurements, without the need to reference an explicit state-space realization of the underlying full-order model. In this work, we generalize the QuadBT framework to other types of balanced truncation model reduction. Namely, we show what transfer function data are required to compute data-driven reduced models by balanced stochastic truncation, positive-real balanced truncation, and bounded-real balanced truncation. In each case, these data are evaluations of particular spectral factors associated with the system of interest. These results lay the theoretical foundation for data-driven reformulations of the aforementioned BT variants. Although it is not yet clear how to compute or obtain these spectral factor data in a practical real-world setting, examples using synthetic (numerically evaluated) transfer function data are included to validate the data-based reduced models.</p></details> | 16 pages, 3 figures |
| **[Reduced basis solvers for unfitted methods on parameterized domains](http://arxiv.org/abs/2508.15320v2)** | 2025-08-24 | <details><summary>Show</summary><p>In this paper, we present a unified framework for reduced basis approximations of parametrized partial differential equations defined on parameter-dependent domains. Our approach combines unfitted finite element methods with both classical and tensor-based reduced basis techniques -- particularly the tensor-train reduced basis method -- to enable efficient and accurate model reduction on general geometries. To address the challenge of reconciling geometric variability with fixed-dimensional snapshot representations, we adopt a deformation-based strategy that maps a reference configuration to each parameterized domain. Furthermore, we introduce a localization procedure to construct dictionaries of reduced subspaces and hyper-reduction approximations, which are obtained via matrix discrete empirical interpolation in our work. We extend the proposed framework to saddle-point problems by adapting the supremizer enrichment strategy to unfitted methods and deformed configurations, demonstrating that the supremizer operator can be defined on the reference configuration without loss of stability. Numerical experiments on two- and three-dimensional problems -- including Poisson, linear elasticity, incompressible Stokes and Navier-Stokes equations -- demonstrate the flexibility, accuracy and efficiency of the proposed methodology.</p></details> | <details><summary>22 pa...</summary><p>22 pages, 7 figures, 5 tables</p></details> |
| **[First and Second Order Optimal $\mathcal{H}_2$ Model Reduction for Linear Continuous-Time Systems](http://arxiv.org/abs/2508.17503v1)** | 2025-08-24 | <details><summary>Show</summary><p>In this paper, we investigate the optimal $\mathcal{H}_2$ model reduction problem for single-input single-output (SISO) continuous-time linear time-invariant (LTI) systems. A semi-definite relaxation (SDR) approach is proposed to determine globally optimal interpolation points, providing an effective way to compute the reduced-order models via Krylov projection-based methods. In contrast to iterative approaches, we use the controllability Gramian and the moment-matching conditions to recast the model reduction problem as a convex optimization by introducing an upper bound $\gamma$ to minimize the $\mathcal{H}_2$ norm of the model reduction error system. We also prove that the relaxation is exact for first order reduced models and demonstrate, through examples, that it is exact for second order reduced models. We compare the performance of our proposed method with other iterative approaches and shift-selection methods on examples. Importantly, our approach also provides a means to verify the global optimality of known locally convergent methods.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures, CDC conference</p></details> |
| **[Stabilization of Parabolic Time-Varying PDEs using Certified Reduced-Order Receding Horizon Control](http://arxiv.org/abs/2508.16801v1)** | 2025-08-22 | <details><summary>Show</summary><p>We address the stabilization of linear, time-varying parabolic PDEs using finite-dimensional receding horizon controls (RHCs) derived from reduced-order models (ROMs). We first prove exponential stability and suboptimality of the continuous-time full-order model (FOM) RHC scheme in Hilbert spaces. A Galerkin model reduction is then introduced, along with a rigorous a posteriori error analysis for the associated finite-horizon optimal control problems. This results in a ROM-based RHC algorithm that adaptively constructs reduced-order controls, ensuring exponential stability of the FOM closed-loop state and providing computable performance bounds with respect to the infinite-horizon FOM control problem. Numerical experiments with a non-smooth cost functional involving the squared l1-norm confirm the methods effectiveness, even for exponentially unstable systems.</p></details> |  |
| **[Stokes-Brinkman-Darcy models for fluid-porous systems: derivation, analysis and validation](http://arxiv.org/abs/2404.16577v2)** | 2025-08-19 | <details><summary>Show</summary><p>Flow interaction between a plain-fluid region in contact with a porous layer attracted significant attention from modelling and analysis sides due to numerous applications in biology, environment and industry. In the most widely used coupled model, fluid flow is described by the Stokes equations in the free-flow domain and Darcy's law in the porous medium, and complemented by the appropriate interface conditions. However, traditional coupling concepts are restricted, with a few exceptions, to one-dimensional flows parallel to the fluid-porous interface. In this work, we use an alternative approach to model interaction between the plain-fluid domain and porous medium by considering a transition zone, and propose the full- and hybrid-dimensional Stokes-Brinkman-Darcy models. In the first case, the equi-dimensional Brinkman equations are considered in the transition region, and the appropriate interface conditions are set on the top and bottom of the transition zone. In the latter case, we perform a dimensional model reduction by averaging the Brinkman equations in the normal direction and using the proposed transmission conditions. The well-posedness of both coupled problems is proved, and some numerical simulations are carried out in order to validate the concepts.</p></details> | <details><summary>23 pa...</summary><p>23 pages, 8 figures, Published in Applied Mathematics and Computation, 2025, DOI:/10.1016/j.amc.2025.129687</p></details> |
| **[Power-Series Approach to Moment-Matching-Based Model Reduction of MIMO Polynomial Nonlinear Systems](http://arxiv.org/abs/2508.13595v1)** | 2025-08-19 | <details><summary>Show</summary><p>The model reduction problem for high-order multi-input, multi-output (MIMO) polynomial nonlinear systems based on moment matching is addressed. The technique of power-series decomposition is exploited: this decomposes the solution of the nonlinear PDE characterizing the center manifold into the solutions of a series of recursively defined Sylvester equations. This approach allows yielding nonlinear reduced-order models in very much the same way as in the linear case (e.g. analytically). Algorithms are proposed for obtaining the order and the parameters of the reduced-order models with precision of degree $\kappa$. The approach also provides new insights into the nonlinear moment matching problem: first, a lower bound for the order of the reduced-order model is obtained, which, in the MIMO case, can be strictly less than the number of matched moments; second, it is revealed that the lower bound is affected by the ratio of the number of the input and output channels; third, it is shown that under mild conditions, a nonlinear reduced-order model can always be constructed with either a linear state equation or a linear output equation.</p></details> |  |
| **[Sum-of-Gaussians tensor neural networks for high-dimensional Schrödinger equation](http://arxiv.org/abs/2508.10454v1)** | 2025-08-14 | <details><summary>Show</summary><p>We propose an accurate, efficient, and low-memory sum-of-Gaussians tensor neural network (SOG-TNN) algorithm for solving the high-dimensional Schr\"odinger equation. The SOG-TNN utilizes a low-rank tensor product representation of the solution to overcome the curse of dimensionality associated with high-dimensional integration. To handle the Coulomb interaction, we introduce an SOG decomposition to approximate the interaction kernel such that it is dimensionally separable, leading to a tensor representation with rapid convergence. We further develop a range-splitting scheme that partitions the Gaussian terms into short-, long-, and mid-range components. They are treated with the asymptotic expansion, the low-rank Chebyshev expansion, and the model reduction with singular-value decomposition, respectively, significantly reducing the number of two-dimensional integrals in computing electron-electron interactions. The SOG decomposition well resolves the computational challenge due to the singularity of the Coulomb interaction, leading to an efficient algorithm for the high-dimensional problem under the TNN framework. Numerical results demonstrate the outstanding performance of the new method, revealing that the SOG-TNN is a promising way for tackling large and complex quantum systems.</p></details> | 22 pages, 6 figures |
| **[Weighted Proper Orthogonal Decomposition for High-Dimensional Optimization](http://arxiv.org/abs/2508.09084v1)** | 2025-08-12 | <details><summary>Show</summary><p>While proper orthogonal decomposition (POD) is widely used for model reduction, its standard form does not take into account any parametric model structure. Extensions to POD have been proposed to address this, but these either require large amounts of solution data, lack online adaptivity, or have limited approximation accuracy. We circumvent these limitations by instead assigning weights to the snapshot matrix columns, and updating these whenever the model is evaluated at a new point in the parameter space. We derive an a posteriori error bound that depends on these snapshot weights, show how these weights can be chosen to tighten the error bound, and present an algorithm to compute the corresponding reduced basis efficiently. We show how this weighted POD approach can be used to naturally generalize the calculation of reduced basis derivatives to situations with multidimensional parameter spaces and snapshots at multiple locations in the parameter space. Lastly, we cover how these approaches can be implemented within an optimization algorithm, without the need for an offline training phase. The proposed weighted POD methods with and without reduced basis derivatives are applied to a gradient-based shell thickness optimization problem with 105 design parameters and a time-dependent partial differential equation. The numerical solutions obtained for this problem attain errors that are several orders of magnitude smaller when using weighted POD than those computed with regular POD and Grassmann manifold interpolation, while having comparable wall times per query and requiring fewer high-dimensional model snapshots to reach an optimal solution.</p></details> | 26 pages, 7 figures |
| **[COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models](http://arxiv.org/abs/2508.08144v1)** | 2025-08-11 | <details><summary>Show</summary><p>The rapid growth of resource-constrained mobile platforms, including mobile robots, wearable systems, and Internet-of-Things devices, has increased the demand for computationally efficient neural network controllers (NNCs) that can operate within strict hardware limitations. While deep neural networks (DNNs) demonstrate superior performance in control applications, their substantial computational complexity and memory requirements present significant barriers to practical deployment on edge devices. This paper introduces a comprehensive model compression methodology that leverages component-aware structured pruning to determine the optimal pruning magnitude for each pruning group, ensuring a balance between compression and stability for NNC deployment. Our approach is rigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC), a state-of-the-art model-based reinforcement learning algorithm, with a systematic integration of mathematical stability guarantee properties, specifically Lyapunov criteria. The key contribution of this work lies in providing a principled framework for determining the theoretical limits of model compression while preserving controller stability. Experimental validation demonstrates that our methodology successfully reduces model complexity while maintaining requisite control performance and stability characteristics. Furthermore, our approach establishes a quantitative boundary for safe compression ratios, enabling practitioners to systematically determine the maximum permissible model reduction before violating critical stability properties, thereby facilitating the confident deployment of compressed NNCs in resource-limited environments.</p></details> | <details><summary>Submi...</summary><p>Submitted in: The 2026 IEEE/SICE International Symposium on System Integration (SII 2026)</p></details> |
| **[Efficient data-driven regression for reduced-order modeling of spatial pattern formation](http://arxiv.org/abs/2508.06833v1)** | 2025-08-09 | <details><summary>Show</summary><p>We present an efficient data-driven regression approach for constructing reduced-order models (ROMs) of reaction-diffusion systems exhibiting pattern formation. The ROMs are learned non-intrusively from available training data of physically accurate numerical simulations. The method can be applied to general nonlinear systems through the use of polynomial model form, while not requiring knowledge of the underlying physical model, governing equations, or numerical solvers. The process of learning ROMs is posed as a low-cost least-squares problem in a reduced-order subspace identified via Proper Orthogonal Decomposition (POD). Numerical experiments on classical pattern-forming systems--including the Schnakenberg and Mimura--Tsujikawa models--demonstrate that higher-order surrogate models significantly improve prediction accuracy while maintaining low computational cost. The proposed method provides a flexible, non-intrusive model reduction framework, well suited for the analysis of complex spatio-temporal pattern formation phenomena.</p></details> |  |
| **[A unified framework for the analysis, numerical approximation and model reduction of linear operator equations, Part I: Well-posedness in space and time](http://arxiv.org/abs/2508.05407v1)** | 2025-08-07 | <details><summary>Show</summary><p>We present a unified framework to construct well-posed formulations for large classes of linear operator equations including elliptic, parabolic and hyperbolic partial differential equations. This general approach incorporates known weak variational formulations as well as novel space-time variational forms of the hyperbolic wave equation. The main concept is completion and extension of operators starting from the strong form of the problem. This paper lays the theoretical foundation for a unified approach towards numerical approximation methods and also model reduction of parameterized linear operator equations which will be the subject of the following parts.</p></details> | <details><summary>linea...</summary><p>linear operator equations, well-posedness, space-time variational methods</p></details> |
| **[State dimension reduction of recurrent equilibrium networks with contraction and robustness preservation](http://arxiv.org/abs/2508.02843v1)** | 2025-08-04 | <details><summary>Show</summary><p>Recurrent equilibrium networks (RENs) are effective for learning the dynamics of complex dynamical systems with certified contraction and robustness properties through unconstrained learning. While this opens the door to learning large-scale RENs, deploying such large-scale RENs in real-time applications on resource-limited devices remains challenging. Since a REN consists of a feedback interconnection of linear time-invariant (LTI) dynamics and static activation functions, this article proposes a projection-based approach to reduce the state dimension of the LTI component of a trained REN. One of the two projection matrices is dedicated to preserving contraction and robustness by leveraging the already-learned REN contraction certificate. The other projection matrix is iteratively updated to improve the accuracy of the reduced-order REN based on necessary $h_2$-optimality conditions for LTI model reduction. Numerical examples validate the approach, demonstrating significant state dimension reduction with limited accuracy loss while preserving contraction and robustness.</p></details> |  |
| **[Model reduction for fully nonlinear stochastic systems](http://arxiv.org/abs/2508.02263v1)** | 2025-08-04 | <details><summary>Show</summary><p>This paper presents a novel model order reduction framework tailored for fully nonlinear stochastic dynamics without lifting them to quadratic systems and without using linearization techniques. By directly leveraging structural properties of the nonlinearities -- such as local and one-sided Lipschitz continuity or one-sided linear growth conditions -- the approach defines generalized reachability and observability Gramians through Lyapunov-type differential operators. These Gramians enable projection-based reduction while preserving essential dynamics and stochastic characteristics. The paper provides sufficient conditions for the existence of these Gramians, including a Lyapunov-based mean square stability criterion, and derives explicit output error bounds for the reduced order models. Furthermore, the work introduces a balancing and truncation procedure for obtaining reduced systems and demonstrates how dominant subspaces can be identified from the spectrum of the Gramians. The theoretical findings are grounded in rigorous stochastic analysis, extending balanced truncation techniques to a broad class of nonlinear systems under stochastic excitation.</p></details> |  |
| **[Kernel-Based Sparse Additive Nonlinear Model Structure Detection through a Linearization Approach](http://arxiv.org/abs/2508.01453v1)** | 2025-08-02 | <details><summary>Show</summary><p>The choice of parameterization in Nonlinear (NL) system models greatly affects the quality of the estimated model. Overly complex models can be impractical and hard to interpret, necessitating data-driven methods for simpler and more accurate representations. In this paper, we propose a data-driven approach to simplify a class of continuous-time NL system models using linear approximations around varying operating points. Specifically, for sparse additive NL models, our method identifies the number of NL subterms and their corresponding input spaces. Under small-signal operation, we approximate the unknown NL system as a trajectory-scheduled Linear Parameter-Varying (LPV) system, with LPV coefficients representing the gradient of the NL function and indicating input sensitivity. Using this sensitivity measure, we determine the NL system's structure through LPV model reduction by identifying non-zero LPV coefficients and selecting scheduling parameters. We introduce two sparse estimators within a vector-valued Reproducing Kernel Hilbert Space (RKHS) framework to estimate the LPV coefficients while preserving their structural relationships. The structure of the sparse additive NL model is then determined by detecting non-zero elements in the gradient vector (LPV coefficients) and the Hessian matrix (Jacobian of the LPV coefficients). We propose two computationally tractable RKHS-based estimators for this purpose. The sparsified Hessian matrix reveals the NL model's structure, with numerical simulations confirming the approach's effectiveness.</p></details> |  |
| **[Low-dimensional observer design for stable linear systems by model reduction](http://arxiv.org/abs/2508.00609v1)** | 2025-08-01 | <details><summary>Show</summary><p>This paper presents a low-dimensional observer design for stable, single-input single-output, continuous-time linear time-invariant (LTI) systems. Leveraging the model reduction by moment matching technique, we approximate the system with a reduced-order model. Based on this reduced-order model, we design a low-dimensional observer that estimates the states of the original system. We show that this observer establishes exact asymptotic state reconstruction for a given class of inputs tied to the observer's dimension. Furthermore, we establish an exponential input-to-state stability property for generic inputs, ensuring a bounded estimation error. Numerical simulations confirm the effectiveness of the approach for a benchmark model reduction problem.</p></details> |  |
| **[Partial Floquet Transformation and Model Order Reduction of Linear Time-Periodic Systems](http://arxiv.org/abs/2508.00221v1)** | 2025-07-31 | <details><summary>Show</summary><p>Time-periodic dynamical systems occur commonly both in nature and as engineered systems. Large-scale linear time-periodic dynamical systems, for example, may arise through linearization of a nonlinear system about a given periodic solution (possibly as a consequence of a baseline periodic forcing) with subsequent spatial discretization. The potential need to simulate responses to a wide variety of input profiles (viewed as perturbations off a baseline periodic forcing) creates a potent incentive for effective model reduction strategies applicable to linear time-periodic (LTP) systems. Classical approaches that take into account the underlying time-periodic system structure often utilize the Floquet transform; however, computation of the Floquet transform is typically intractable for large order systems. In this paper, we develop the notion of a partial Floquet transformation connected to selected invariant subspaces of a time-varying differential operator associated with the LTP system. We modify and repurpose the Dominant Pole Algorithm of Rommes to identify effective invariant subspaces useful for model reduction. We discuss the construction of associated partial Floquet transformations and time-varying reduction bases with which to produce effective reduced-order LTP models and illustrate the process on a simple time-periodic system.</p></details> | 21 pages |
| **[Tensor-based reduction of linear parameter-varying state-space models](http://arxiv.org/abs/2507.23591v1)** | 2025-07-31 | <details><summary>Show</summary><p>The Linear Parameter-Varying (LPV) framework is a powerful tool for controlling nonlinear and complex systems, but the conversion of nonlinear models into LPV forms often results in high-dimensional and overly conservative LPV models. To be able to apply control strategies, there is often a need for model reduction in order to reduce computational needs. This paper presents the first systematic approach for the joint reduction of state order and scheduling signal dimension of LPV state space models. The existing methods typically address these reductions separately. By formulating a tensorial form of LPV models with an affine dependency on the scheduling variables, we leverage tensor decomposition to find the dominant components of state and scheduling subspaces. We extend the common Petrov-Galerkin projection approach to LPV framework by adding a scheduling projection. This extension enables the joint reduction. To find suitable subspaces for the extended Petrov-Galerkin projection, we have developed two different methods: tensor-based LPV moment matching, and an approach through Proper Orthogonal Decomposition. Advantages of the proposed methods are demonstrated on two different series-interconnected mass-spring-damper systems with nonlinear springs: one primarily used for comparison with other methods and a more elaborate higher-order model designed to assess scalability.</p></details> |  |
| **[Structure-Preserving Discretization and Model Reduction for Energy-Based Models](http://arxiv.org/abs/2507.21552v1)** | 2025-07-29 | <details><summary>Show</summary><p>We investigate discretization strategies for a recently introduced class of energy-based models. The model class encompasses classical port-Hamiltonian systems, generalized gradient flows, and certain systems with algebraic constraints. Our framework combines existing ideas from the literature and systematically addresses temporal discretization, spatial discretization, and model order reduction, ensuring that all resulting schemes are dissipation-preserving in the sense of a discrete dissipation inequality. For this, we use a Petrov-Galerkin ansatz together with appropriate projections. Numerical results for a nonlinear circuit model and the Cahn-Hilliard equation illustrate the effectiveness of the approach.</p></details> | 20 pages, 5 figures |
| **[PySHRED: A Python package for SHallow REcurrent Decoding for sparse sensing, model reduction and scientific discovery](http://arxiv.org/abs/2507.20954v1)** | 2025-07-28 | <details><summary>Show</summary><p>SHallow REcurrent Decoders (SHRED) provide a deep learning strategy for modeling high-dimensional dynamical systems and/or spatiotemporal data from dynamical system snapshot observations. PySHRED is a Python package that implements SHRED and several of its major extensions, including for robust sensing, reduced order modeling and physics discovery. In this paper, we introduce the version 1.0 release of PySHRED, which includes data preprocessors and a number of cutting-edge SHRED methods specifically designed to handle real-world data that may be noisy, multi-scale, parameterized, prohibitively high-dimensional, and strongly nonlinear. The package is easy to install, thoroughly-documented, supplemented with extensive code examples, and modularly-structured to support future additions. The entire codebase is released under the MIT license and is available at https://github.com/pyshred-dev/pyshred.</p></details> | 15 pages, 9 figures |
| **[Operator Inference Aware Quadratic Manifolds with Isotropic Reduced Coordinates for Nonintrusive Model Reduction](http://arxiv.org/abs/2507.20463v1)** | 2025-07-28 | <details><summary>Show</summary><p>Quadratic manifolds for nonintrusive reduced modeling are typically trained to minimize the reconstruction error on snapshot data, which means that the error of models fitted to the embedded data in downstream learning steps is ignored. In contrast, we propose a greedy training procedure that takes into account both the reconstruction error on the snapshot data and the prediction error of reduced models fitted to the data. Because our procedure learns quadratic manifolds with the objective of achieving accurate reduced models, it avoids oscillatory and other non-smooth embeddings that can hinder learning accurate reduced models. Numerical experiments on transport and turbulent flow problems show that quadratic manifolds trained with the proposed greedy approach lead to reduced models with up to two orders of magnitude higher accuracy than quadratic manifolds trained with respect to the reconstruction error alone.</p></details> | 23 pages, 8 figures |
| **[Symmetry-reduced model reduction of shift-equivariant systems via operator inference](http://arxiv.org/abs/2507.18780v1)** | 2025-07-24 | <details><summary>Show</summary><p>We consider data-driven reduced-order models of partial differential equations with shift equivariance. Shift-equivariant systems typically admit traveling solutions, and the main idea of our approach is to represent the solution in a traveling reference frame, in which it can be described by a relatively small number of basis functions. Existing methods for operator inference allow one to approximate a reduced-order model directly from data, without knowledge of the full-order dynamics. Our method adds additional terms to ensure that the reduced-order model not only approximates the spatially frozen profile of the solution, but also estimates the traveling speed as a function of that profile. We validate our approach using the Kuramoto-Sivashinsky equation, a one-dimensional partial differential equation that exhibits traveling solutions and spatiotemporal chaos. Results indicate that our method robustly captures traveling solutions, and exhibits improved numerical stability over the standard operator inference approach.</p></details> | <details><summary>30 pa...</summary><p>30 pages, 7 figures. Orally presented at the SIAM Conference on Applications of Dynamical Systems (SIAM DS25). Submitted to Advances in Computational Mathematics (ACOM)</p></details> |
| **[Exact Model Reduction for Continuous-Time Open Quantum Dynamics](http://arxiv.org/abs/2412.05102v3)** | 2025-07-23 | <details><summary>Show</summary><p>We consider finite-dimensional many-body quantum systems described by time-independent Hamiltonians and Markovian master equations, and present a systematic method for constructing smaller-dimensional, reduced models that exactly reproduce the time evolution of a set of initial conditions or observables of interest. Our approach exploits Krylov operator spaces and their extension to operator algebras, and may be used to obtain reduced linear models of minimal dimension, well-suited for simulation on classical computers, or reduced quantum models that preserve the structural constraints of physically admissible quantum dynamics, as required for simulation on quantum computers. Notably, we prove that the reduced quantum-dynamical generator is still in Lindblad form. By introducing a new type of observable-dependent symmetries, we show that our method provides a non-trivial generalization of techniques that leverage symmetries, unlocking new reduction opportunities. We quantitatively benchmark our method on paradigmatic open many-body systems of relevance to condensed-matter and quantum-information physics. In particular, we demonstrate how our reduced models can quantitatively describe decoherence dynamics in central-spin systems coupled to structured environments, magnetization transport in boundary-driven dissipative spin chains, and unwanted error dynamics on information encoded in a noiseless quantum code.</p></details> |  |
| **[Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies](http://arxiv.org/abs/2507.14901v1)** | 2025-07-20 | <details><summary>Show</summary><p>Why do reinforcement learning (RL) policies fail or succeed? This is a challenging question due to the complex, high-dimensional nature of agent-environment interactions. In this work, we take a causal perspective on explaining the behavior of RL policies by viewing the states, actions, and rewards as variables in a low-level causal model. We introduce random perturbations to policy actions during execution and observe their effects on the cumulative reward, learning a simplified high-level causal model that explains these relationships. To this end, we develop a nonlinear Causal Model Reduction framework that ensures approximate interventional consistency, meaning the simplified high-level model responds to interventions in a similar way as the original complex system. We prove that for a class of nonlinear causal models, there exists a unique solution that achieves exact interventional consistency, ensuring learned explanations reflect meaningful causal patterns. Experiments on both synthetic causal models and practical RL tasks-including pendulum control and robot table tennis-demonstrate that our approach can uncover important behavioral patterns, biases, and failure modes in trained RL policies.</p></details> |  |
| **[Expansive Natural Neural Gradient Flows for Energy Minimization](http://arxiv.org/abs/2507.13475v1)** | 2025-07-17 | <details><summary>Show</summary><p>This paper develops expansive gradient dynamics in deep neural network-induced mapping spaces. Specifically, we generate tools and concepts for minimizing a class of energy functionals in an abstract Hilbert space setting covering a wide scope of applications such as PDEs-based inverse problems and supervised learning. The approach hinges on a Hilbert space metric in the full diffeomorphism mapping space, which could be viewed as a generalized Wasserstein-2 metric. We then study a projection gradient descent method within deep neural network parameterized sets. More importantly, we develop an adaptation and expanding strategy to step-by-step enlarge the deep neural network structures. In particular, the expansion mechanism aims to enhance the alignment of the neural manifold induced natural gradient direction as well as possible with the ideal Hilbert space gradient descent direction leveraging the fact that we can evaluate projections of the Hilbert space gradient. We demonstrate the efficacy of the proposed strategy for several simple model problems for energies arising in the context of supervised learning, model reduction, or inverse problems. In particular, we highlight the importance of assembling the neural flow matrix based on the inner product for the ambient Hilbert space. The actual algorithms are the simplest specifications of a broader spectrum based on a correspondingly wider discussion, postponing a detailed analysis to forthcoming work.</p></details> | 40 pages, 19 figures |
| **[Non-intrusive model reduction of advection-dominated hyperbolic problems using neural network shift augmented manifold transformation](http://arxiv.org/abs/2407.18419v3)** | 2025-07-15 | <details><summary>Show</summary><p>Advection-dominated problems are predominantly noticed in nature, engineering systems, and various industrial processes. Traditional linear compression methods, such as proper orthogonal decomposition (POD) and reduced basis (RB) methods are ill-suited for these problems, due to slow Kolmogorov $n$-width decay. This results in inefficient and inaccurate reduced order models (ROMs). There are few non-linear approaches to accelerate the Kolmogorov $n$-width decay. In this work, we use a neural network shift augmented transformation technique that employs automatic shift detection. This approach leverages a deep-learning framework to derive a parameter-dependent mapping between the original manifold $\mathcal{M}$ and the transformed manifold $\tilde{\mathcal{M}}$. We apply a linear compression method to obtain a low-dimensional linear approximation subspace of the transformed manifold $\tilde{\mathcal{M}}$. Furthermore, we construct non-intrusive reduced order models on the resulting transformed linear approximation subspace and employ automatic shift detection for predictions in the online stage. We propose a complete framework, the neural network shift-augmented proper orthogonal decomposition-based reduced order model (NNsPOD-ROM) algorithm, comprising both offline and online stages for model reduction of advection-dominated problems. We test our proposed methodology on numerous experiments to evaluate its performance on the 1D linear advection equation, a higher order method benchmark case - the 2D isentropic convective vortex, and 2D two-phase flow.</p></details> | 22 pages, 19 Figures |
| **[Kernel-based Greedy Approximation of Parametric Elliptic Boundary Value Problems](http://arxiv.org/abs/2507.06731v1)** | 2025-07-09 | <details><summary>Show</summary><p>We recently introduced a scale of kernel-based greedy schemes for approximating the solutions of elliptic boundary value problems. The procedure is based on a generalized interpolation framework in reproducing kernel Hilbert spaces and was coined PDE-$\beta$-greedy procedure, where the parameter $\beta \geq 0$ is used in a greedy selection criterion and steers the degree of function adaptivity. Algebraic convergence rates have been obtained for Sobolev-space kernels and solutions of finite smoothness. We now report a result of exponential convergence rates for the case of infinitely smooth kernels and solutions. We furthermore extend the approximation scheme to the case of parametric PDEs by the use of state-parameter product kernels. In the surrogate modelling context, the resulting approach can be interpreted as an a priori model reduction approach, as no solution snapshots need to be precomputed. Numerical results show the efficiency of the approximation procedure for problems which occur as challenges for other parametric MOR procedures: non-affine geometry parametrizations, moving sources or high-dimensional domains.</p></details> |  |
| **[Gramians for a New Class of Nonlinear Control Systems Using Koopman and a Novel Generalized SVD](http://arxiv.org/abs/2507.04188v1)** | 2025-07-05 | <details><summary>Show</summary><p>Model reduction with error bounds in nonlinear systems with non-affine control inputs remains an active field of research. In this work we present a construction for Controllability and Observability Gramians in a class of non-affine control input systems satisfying certain induced norm properties. We do so using a combination of representational forms, including a novel function decomposition that resembles linear Singular Value Decomposition (SVD), in tandem with an additional unconventional decomposition of the dynamics, and Koopman operator theory. The resulting representation allows one to place error bounds on the $H_{\infty}$ norm on a reduced-order representation of the system computed using finite-dimensional nonlinear Controllability and Observability Gramians.</p></details> |  |
| **[An ensemble Kalman approach to randomized maximum likelihood estimation](http://arxiv.org/abs/2507.03207v1)** | 2025-07-03 | <details><summary>Show</summary><p>This work proposes ensemble Kalman randomized maximum likelihood estimation, a new derivative-free method for performing randomized maximum likelihood estimation, which is a method that can be used to generate approximate samples from posterior distributions in Bayesian inverse problems. The new method has connections to ensemble Kalman inversion and works by evolving an ensemble so that each ensemble member solves an instance of a randomly perturbed optimization problem. Linear analysis demonstrates that ensemble members converge exponentially fast to randomized maximum likelihood estimators and, furthermore, that the new method produces samples from the Bayesian posterior when applied to a suitably regularized optimization problem. The method requires that the forward operator, relating the unknown parameter to the data, be evaluated once per iteration per ensemble member, which can be prohibitively expensive when the forward model requires the evolution of a high-dimensional dynamical system. We propose a strategy for making the proposed method tractable in this setting based on a balanced truncation model reduction method tailored to the Bayesian smoothing problem. Theoretical results show near-optimality of this model reduction approach via convergence to an optimal approximation of the posterior covariance as a low-rank update to the prior covariance. Numerical experiments verify theoretical results and illustrate computational acceleration through model reduction.</p></details> | 34 pages, 4 figures |
| **[Structure-preserving Lift & Learn: Scientific machine learning for nonlinear conservative partial differential equations](http://arxiv.org/abs/2507.00301v1)** | 2025-06-30 | <details><summary>Show</summary><p>This work presents structure-preserving Lift & Learn, a scientific machine learning method that employs lifting variable transformations to learn structure-preserving reduced-order models for nonlinear partial differential equations (PDEs) with conservation laws. We propose a hybrid learning approach based on a recently developed energy-quadratization strategy that uses knowledge of the nonlinearity at the PDE level to derive an equivalent quadratic lifted system with quadratic system energy. The lifted dynamics obtained via energy quadratization are linear in the old variables, making model learning very effective in the lifted setting. Based on the lifted quadratic PDE model form, the proposed method derives quadratic reduced terms analytically and then uses those derived terms to formulate a constrained optimization problem to learn the remaining linear reduced operators in a structure-preserving way. The proposed hybrid learning approach yields computationally efficient quadratic reduced-order models that respect the underlying physics of the high-dimensional problem. We demonstrate the generalizability of quadratic models learned via the proposed structure-preserving Lift & Learn method through three numerical examples: the one-dimensional wave equation with exponential nonlinearity, the two-dimensional sine-Gordon equation, and the two-dimensional Klein-Gordon-Zakharov equations. The numerical results show that the proposed learning approach is competitive with the state-of-the-art structure-preserving data-driven model reduction method in terms of both accuracy and computational efficiency.</p></details> | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2503.02273</p></details> |
| **[Dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances](http://arxiv.org/abs/2506.23892v1)** | 2025-06-30 | <details><summary>Show</summary><p>Bayesian inverse problems use observed data to update a prior probability distribution for an unknown state or parameter of a scientific system to a posterior distribution conditioned on the data. In many applications, the unknown parameter is high-dimensional, making computation of the posterior expensive due to the need to sample in a high-dimensional space and the need to evaluate an expensive high-dimensional forward model relating the unknown parameter to the data. However, inverse problems often exhibit low-dimensional structure due to the fact that the available data are only informative in a low-dimensional subspace of the parameter space. Dimension reduction approaches exploit this structure by restricting inference to the low-dimensional subspace informed by the data, which can be sampled more efficiently. Further computational cost reductions can be achieved by replacing expensive high-dimensional forward models with cheaper lower-dimensional reduced models. In this work, we propose new dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances, which arise in many practical inference settings. The dimension reduction approach is applicable to general linear Bayesian inverse problems whereas the model reduction approaches are specific to the problem of inferring the initial condition of a linear dynamical system. We provide theoretical approximation guarantees as well as numerical experiments demonstrating the accuracy and efficiency of the proposed approaches.</p></details> |  |
| **[Subspace-Distance-Enabled Active Learning for Efficient Data-Driven Model Reduction of Parametric Dynamical Systems](http://arxiv.org/abs/2505.00460v2)** | 2025-06-25 | <details><summary>Show</summary><p>In situations where the solution of a high-fidelity dynamical system needs to be evaluated repeatedly, over a vast pool of parametric configurations and in absence of access to the underlying governing equations, data-driven model reduction techniques are preferable. We propose a novel active learning approach to build a parametric data-driven reduced-order model (ROM) by greedily picking the most important parameter samples from the parameter domain. As a result, during the ROM construction phase, the number of high-fidelity solutions dynamically grow in a principled fashion. The high-fidelity solution snapshots are expressed in several parameter-specific linear subspaces, with the help of proper orthogonal decomposition (POD), and the relative distance between these subspaces is used as a guiding mechanism to perform active learning. For successfully achieving this, we provide a distance measure to evaluate the similarity between pairs of linear subspaces with different dimensions, and also show that this distance measure is a metric. The usability of the proposed subspace-distance-enabled active learning (SDE-AL) framework is demonstrated by augmenting two existing non-intrusive reduced-order modeling approaches, and providing their active-learning-driven (ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN. Furthermore, we report positive results for two parametric physical models, highlighting the efficiency of the proposed SDE-AL approach.</p></details> | <details><summary>31 pa...</summary><p>31 pages, 10 figures, 4 tables; v2: minor improvements</p></details> |
| **[A parametric tensor ROM for the shallow water dam break problem](http://arxiv.org/abs/2506.20007v1)** | 2025-06-24 | <details><summary>Show</summary><p>We develop a variant of a tensor reduced-order model (tROM) for the parameterized shallow-water dam-break problem. This hyperbolic system presents multiple challenges for model reduction, including a slow decay of the Kolmogorov $N$-width of the solution manifold, shock formation, and the loss of smooth solution dependence on parameters. These issues limit the performance of traditional Proper Orthogonal Decomposition based ROMs. Our tROM approach, based on a low-rank tensor decomposition, builds a parameter-to-solution map from high-fidelity snapshots and constructs localized reduced bases via a local POD procedure. We apply this method to both dry-bed and wet-bed problem setups, showing that the non-interpolatory variant of the tROM, combined with Chebyshev sampling near critical parameter values, effectively captures parameter-dependent behavior and significantly outperforms standard POD-ROMs. This is especially evident in the wet-bed case, where POD-ROMs exhibit poor resolution of shock waves and spurious oscillations.</p></details> |  |
| **[Model Reduction of Homogeneous Polynomial Dynamical Systems via Tensor Decomposition](http://arxiv.org/abs/2506.19165v1)** | 2025-06-23 | <details><summary>Show</summary><p>Model reduction plays a critical role in system control, with established methods such as balanced truncation widely used for linear systems. However, extending these methods to nonlinear settings, particularly polynomial dynamical systems that are often used to model higher-order interactions in physics, biology, and ecology, remains a significant challenge. In this article, we develop a novel model reduction method for homogeneous polynomial dynamical systems (HPDSs) with linear input and output grounded in tensor decomposition. Leveraging the inherent tensor structure of HPDSs, we construct reduced models by extracting dominant mode subspaces via higher-order singular value decomposition. Notably, we establish that key system-theoretic properties, including stability, controllability, and observability, are preserved in the reduced model. We demonstrate the effectiveness of our method using numerical examples.</p></details> |  |
| **[Maximum volume coordinates for Grassmann interpolation: Lagrange, Hermite, and errors](http://arxiv.org/abs/2506.01574v2)** | 2025-06-20 | <details><summary>Show</summary><p>We present a novel approach to Riemannian interpolation on the Grassmann manifold. Instead of relying on the Riemannian normal coordinates, i.e. the Riemannian exponential and logarithm maps, we approach the interpolation problem with an alternative set of local coordinates and corresponding parameterizations. A special property of these coordinates is that their calculation does not require any matrix decompositions. This is a numerical advantage over Riemann normal coordinates and many other retractions on the Grassmann manifold, especially when derivative data are to be treated. To estimate the interpolation error, we examine the conditioning of these mappings and state explicit bounds. It turns out that the parameterizations are well-conditioned, but the coordinate mappings are generally not. As a remedy, we introduce maximum-volume coordinates that are based on a search for subblocks of column-orthogonal matrices of large absolute determinant. We show that the order of magnitude of the asymptotic interpolation error on $\Gr(n,p)$ is the same as in the Euclidean space. Two numerical experiments are conducted. The first is an academic one, where we interpolate a parametric orthogonal projector $QQ^T$, where the $Q$--factor stems from a parametric compact QR--decomposition. The second experiment is in the context of parametric model reduction of dynamical systems, where we interpolate reduced subspaces that are obtained by proper orthogonal decomposition.</p></details> | 34 pages, 6 figures |
| **[Model Reduction of a Flexible Nonsmooth Oscillator Recovers its Entire Bifurcation Structure](http://arxiv.org/abs/2311.17947v4)** | 2025-06-19 | <details><summary>Show</summary><p>We study the reduced order modeling of a piecewise-linear, globally nonlinear flexible oscillator in which a Bernoulli-Euler beam is subjected to a position-triggered kick force and a piecewise restoring force at its tip. The nonsmooth boundary conditions, which determine different regions of a hybrid phase space, can generally be expected to excite many degrees of freedom. With kick strength as parameter, the system's bifurcation diagram is found to exhibit a range of periodic and chaotic behaviors. Proper orthogonal decomposition (POD) is used to obtain a single set of global basis functions spanning all of the hybrid regions. The reduced order model (ROM) dimension is chosen using previously developed energy closure analysis, ensuring approximate energy balance on the reduced subspace. This yields accurate ROMs with 8 degrees of freedom. Remarkably, we find that ROMs formulated using using data from individual periodic steady states can nevertheless be used to reconstruct the entire bifurcation structure of the original system without updating. This demonstrates that, despite being constructed with steady state data, the ROMs model sufficiently small transients with enough accuracy to permit using simple continuation for the bifurcation diagram. We also find ROM subspaces obtained for different values of the bifurcation parameter are essentially identical. Thus, POD augmented with energy closure analysis is found to reliably yield effective dimension estimates and ROMs for this nonlinear, nonsmooth system that are robust across stability transitions, including even period doubling cascades to chaos, thereby greatly reducing data requirements and computational costs.</p></details> | 32 pages, 8 figures |
| **[Data-Driven Model Reduction by Moment Matching for Linear and Nonlinear Parametric Systems](http://arxiv.org/abs/2506.10866v1)** | 2025-06-12 | <details><summary>Show</summary><p>Theory and methods to obtain parametric reduced-order models by moment matching are presented. The definition of the parametric moment is introduced, and methods (model-based and data-driven) for the approximation of the parametric moment of linear and nonlinear parametric systems are proposed. These approximations are exploited to construct families of parametric reduced-order models that match the approximate parametric moment of the system to be reduced and preserve key system properties such as asymptotic stability and dissipativity. The use of the model reduction methods is illustrated by means of a parametric benchmark model for the linear case and a large-scale wind farm model for the nonlinear case. In the illustration, a comparison of the proposed approximation methods is drawn and their advantages/disadvantages are discussed.</p></details> | <details><summary>16 pa...</summary><p>16 pages, 6 figures, submitted to IEEE Transactions on Automatic Control</p></details> |
| **[Multiscale model reduction and two-level Schwarz preconditioner for H(curl) elliptic problems](http://arxiv.org/abs/2506.07381v1)** | 2025-06-09 | <details><summary>Show</summary><p>This paper addresses the efficient solution of linear systems arising from curl-conforming finite element discretizations of $H(\mathrm{curl})$ elliptic problems with heterogeneous coefficients. We first employ the discrete form of a multiscale spectral generalized finite element method (MS-GFEM) for model reduction and prove that the method exhibits exponential convergence with respect to the number of local degrees of freedom. The proposed method and its convergence analysis are applicable in broad settings, including general heterogeneous ($L^{\infty}$) coefficients, domains and subdomains with nontrivial topology, irregular subdomain geometries, and high-order finite element discretizations. Furthermore, we formulate the method as an iterative solver, yielding a two-level restricted additive Schwarz type preconditioner based on the MS-GFEM coarse space. The GMRES algorithm, applied to the preconditioned system, is shown to converge at a rate of at least $\Lambda$, where $\Lambda$ denotes the error bound of the discrete MS-GFEM approximation. Numerical experiments in both two and three dimensions demonstrate the superior performance of the proposed methods in terms of dimensionality reduction.</p></details> |  |
| **[Energy-stable Port-Hamiltonian Systems](http://arxiv.org/abs/2506.06471v1)** | 2025-06-06 | <details><summary>Show</summary><p>We combine energy-stable and port-Hamiltonian (pH) systems to obtain energy-stable port-Hamiltonian (espH) systems. The idea is to extend the known energy-stable systems with an input-output port, which results in a pH formulation. One advantage of the new espH formulation is that it naturally preserves its espH structure throughout discretization (in space and time) and model reduction.</p></details> | 10 pages |
| **[Model Reduction for Transport-Dominated Problems via Cross-Correlation Based Snapshot Registration](http://arxiv.org/abs/2501.01299v2)** | 2025-06-04 | <details><summary>Show</summary><p>Traditional linear approximation methods, such as proper orthogonal decomposition and the reduced basis method, are ill-suited for transport-dominated problems due to the slow decay of the Kolmogorov $n$-width, leading to inefficient and inaccurate reduced-order models. In this work, we propose a model reduction approach for transport-dominated problems by employing cross-correlation based snapshot registration to accelerate the Kolmogorov $n$-width decay, thereby enabling the construction of efficient and accurate reduced-order models using linear approximation methods. We propose a complete framework comprising offline-online stages for the development of reduced order models using the cross-correlation based snapshots registration. The effectiveness of the proposed approach is demonstrated using two test cases: 1D travelling waves and the higher-order methods benchmark test case, 2D isentropic convective vortex.</p></details> |  |
| **[An iterative tangential interpolation framework for model reduction of MIMO systems](http://arxiv.org/abs/2506.03410v1)** | 2025-06-03 | <details><summary>Show</summary><p>We consider model reduction of large-scale MIMO systems using tangential interpolation in the frequency domain. Our scheme is related to the recently-developed Adaptive Antoulas--Anderson (AAA) algorithm, which is an iterative algorithm that uses concepts from the Loewner framework. Our algorithm uses low-rank interpolation and iteratively adds interpolation points based on several criteria including minimizing maximum errors. We show there is freedom in the interpolation point selection method, leading to multiple algorithms that have trade-offs between computational complexity and approximation performance. We prove that a weighted \(H_2\) norm of a representative error system is monotonically decreasing as interpolation points are added. Finally, we provide computational results and some comparisons with prior works, demonstrating performance on par with standard model reduction methods.</p></details> | <details><summary>13 pa...</summary><p>13 pages, 4 figures Submitted to IEEE TAC</p></details> |
| **[AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models](http://arxiv.org/abs/2505.24784v1)** | 2025-05-30 | <details><summary>Show</summary><p>Current deep reinforcement learning (DRL) approaches achieve state-of-the-art performance in various domains, but struggle with data efficiency compared to human learning, which leverages core priors about objects and their interactions. Active inference offers a principled framework for integrating sensory information with prior knowledge to learn a world model and quantify the uncertainty of its own beliefs and predictions. However, active inference models are usually crafted for a single task with bespoke knowledge, so they lack the domain flexibility typical of DRL approaches. To bridge this gap, we propose a novel architecture that integrates a minimal yet expressive set of core priors about object-centric dynamics and interactions to accelerate learning in low-data regimes. The resulting approach, which we call AXIOM, combines the usual data efficiency and interpretability of Bayesian approaches with the across-task generalization usually associated with DRL. AXIOM represents scenes as compositions of objects, whose dynamics are modeled as piecewise linear trajectories that capture sparse object-object interactions. The structure of the generative model is expanded online by growing and learning mixture models from single events and periodically refined through Bayesian model reduction to induce generalization. AXIOM masters various games within only 10,000 interaction steps, with both a small number of parameters compared to DRL, and without the computational expense of gradient-based optimization.</p></details> | <details><summary>10 pa...</summary><p>10 pages main text, 4 figures, 2 tables; 25 pages supplementary material, 8 figures</p></details> |
| **[Structure Identification of NDS with Descriptor Subsystems under Asynchronous, Non-Uniform, and Slow-Rate Sampling](http://arxiv.org/abs/2503.20319v2)** | 2025-05-28 | <details><summary>Show</summary><p>Networked dynamic systems (NDS) exhibit collective behavior shaped by subsystem dynamics and complex interconnections, yet identifying these interconnections remains challenging due to irregularities in sampled data, including asynchronous, non-uniform, and low-rate sampling. This paper proposes a novel two-stage structure identification algorithm that leverages system zero-order moments, a concept traditionally used in model order reduction, to bridge system identification and model reduction. First, zero-order moments are estimated from steady-state time-domain outputs; second, subsystem interconnections are explicitly reconstructed from these moments. The method generalizes existing approaches by handling asynchronous, non-uniform, and slow sampling simultaneously, eliminating constraints on input signal periodicity and extending applicability to multi-input multi-output NDS with arbitrary interconnections. Unlike black-box identification techniques, our approach explicitly recovers subsystem interconnection structures. Validation on the IEEE 14-bus system demonstrates the algorithm's effectiveness in recovering subsystem interconnections from irregular sampling data.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 3 figures, cdc2025</p></details> |
| **[Least Squares Model Reduction: A Two-Stage System-Theoretic Interpretation](http://arxiv.org/abs/2505.20604v1)** | 2025-05-27 | <details><summary>Show</summary><p>Model reduction simplifies complex dynamical systems while preserving essential properties. This paper revisits a recently proposed system-theoretic framework for least squares moment matching. It interprets least squares model reduction in terms of two steps process: constructing a surrogate model to satisfy interpolation constraints, then projecting it onto a reduced-order space. Using tools from output regulation theory and Krylov projections, this approach provides a new view on classical methods. For illustration, we reexamine the least-squares model reduction method by Lucas and Smith, offering new insights into its structure.</p></details> | <details><summary>13th ...</summary><p>13th IFAC Symposium on Nonlinear Control Systems. arXiv admin note: substantial text overlap with arXiv:2110.06072</p></details> |
| **[EGPT-PINN: Entropy-enhanced Generative Pre-Trained Physics Informed Neural Networks for parameterized nonlinear conservation laws](http://arxiv.org/abs/2501.01587v2)** | 2025-05-25 | <details><summary>Show</summary><p>We propose an entropy-enhanced Generative Pre-Trained Physics-Informed Neural Network with a transform layer (EGPT-PINN) for solving parameterized nonlinear conservation laws. The EGPT-PINN extends the traditional physics-informed neural networks and its recently proposed generative pre-trained strategy for linear model reduction to nonlinear model reduction and shock-capturing domains. By utilizing an adaptive meta-network, a simultaneously trained transform layer, entropy enhancement strategies, implementable shock interaction analysis, and a separable training process, the EGPT-PINN efficiently captures complex parameter-dependent shock formations and interactions. Numerical results of EGPT-PINN applied to the families of inviscid Burgers' equation and the Euler equations, parameterized by their initial conditions, demonstrate the robustness and accuracy of the proposed technique. It accurately solves the viscosity solution via very few neurons without leveraging any {\it a priori} knowledge of the equations or its initial condition. Moreover, via a simple augmentation of the loss function by model-data mismatch, we demonstrate the robustness of EGPT-PINN in solving inverse problems more accurately than the vanilla and entropy-enhanced versions of PINN.</p></details> | 24 pages,12 figures |
| **[Automatic and Structure-Aware Sparsification of Hybrid Neural ODEs](http://arxiv.org/abs/2505.18996v1)** | 2025-05-25 | <details><summary>Show</summary><p>Hybrid neural ordinary differential equations (neural ODEs) integrate mechanistic models with neural ODEs, offering strong inductive bias and flexibility, and are particularly advantageous in data-scarce healthcare settings. However, excessive latent states and interactions from mechanistic models can lead to training inefficiency and over-fitting, limiting practical effectiveness of hybrid neural ODEs. In response, we propose a new hybrid pipeline for automatic state selection and structure optimization in mechanistic neural ODEs, combining domain-informed graph modifications with data-driven regularization to sparsify the model for improving predictive performance and stability while retaining mechanistic plausibility. Experiments on synthetic and real-world data show improved predictive performance and robustness with desired sparsity, establishing an effective solution for hybrid model reduction in healthcare applications.</p></details> |  |
| **[A New Fick-Jacobs Derivation with Applications to Computational Branched Diffusion Networks](http://arxiv.org/abs/2501.08247v2)** | 2025-05-22 | <details><summary>Show</summary><p>The Fick-Jacobs equation is a classical model reduction of 3-dimensional diffusion in a tube of varying radius to a 1-dimensional problem with radially scaled derivatives. This model has been shown to be unstable when the radial gradient is too steep. In this work, we present a new derivation of the Fick-Jacobs equation that results in the addition of higher order spatial derivative terms that provide additional stability in a wide variety of cases and improved solution convergence. We also derive new numerical schemes for branched nodes within networks and provide stability conditions for these schemes. The computational accuracy, efficiency, and stability of our method is demonstrated through a variety of numerical examples.</p></details> | 23 pages, 15 figures |
| **[Neural empirical interpolation method for nonlinear model reduction](http://arxiv.org/abs/2406.03562v2)** | 2025-05-11 | <details><summary>Show</summary><p>In this paper, we introduce the neural empirical interpolation method (NEIM), a neural network-based alternative to the discrete empirical interpolation method for reducing the time complexity of computing the nonlinear term in a reduced order model (ROM) for a parameterized nonlinear partial differential equation. NEIM is a greedy algorithm which accomplishes this reduction by approximating an affine decomposition of the nonlinear term of the ROM, where the vector terms of the expansion are given by neural networks depending on the ROM solution, and the coefficients are given by an interpolation of some "optimal" coefficients. Because NEIM is based on a greedy strategy, we are able to provide a basic error analysis to investigate its performance. NEIM has the advantages of being easy to implement in models with automatic differentiation, of being a nonlinear projection of the ROM nonlinearity, of being efficient for both nonlocal and local nonlinearities, and of relying solely on data and not the explicit form of the ROM nonlinearity. We demonstrate the effectiveness of the methodology on solution-dependent and solution-independent nonlinearities, a nonlinear elliptic problem, and a nonlinear parabolic model of liquid crystals. Code availability: https://github.com/maxhirsch/NEIM</p></details> |  |
| **[Application of a Novel Model Reduction Technique to the Assessment of Boundedness/Stability of Some Delay Time-Varying Vector Nonlinear Systems](http://arxiv.org/abs/2401.11398v2)** | 2025-05-10 | <details><summary>Show</summary><p>Assessing the boundedness and stability of vector nonlinear systems with variable delays and coefficients remains a challenging problem with broad applications in science and engineering. Existing methods tend to produce overly conservative criteria that offer limited practical value and often fail to explicitly characterize the temporal evolution of solution norms. This paper presents a novel framework for evaluating the evolution of solution norms in such systems. This approach constructs scalar counterparts for the original vector equations. We prove that the solutions to these scalar nonlinear equations, which also include delays and variable coefficients, provide upper bounds for the norms of the original solutions, if the history functions for both equations are properly matched. This reduction enables the evaluation of the boundedness and stability of vector systems through the analysis of the dynamics of their scalar counterparts, which can be performed via straightforward simulations or simplified analytical reasoning. Consequently, we introduce new criteria for boundedness and stability and estimate the radii of the balls containing history functions that yield bounded or stable solutions for the original vector systems. Finally, we validated our inferences through representative simulations that also assessed the accuracy of the proposed approach.</p></details> | 18 pages |
| **[Development of Reduced Feeder and Load Models Using Practical Topological and Loading Data](http://arxiv.org/abs/2505.06439v1)** | 2025-05-09 | <details><summary>Show</summary><p>Distribution feeder and load model reduction methods are essential for maintaining a good tradeoff between accurate representation of grid behavior and reduced computational complexity in power system studies. An effective algorithm to obtain a reduced order representation of the practical feeders using utility topological and loading data has been presented in this paper. Simulations conducted in this work show that the reduced feeder and load model of a utility feeder, obtained using the proposed method, can accurately capture contactor and motor stalling behaviors for critical events such as fault induced delayed voltage recovery.</p></details> |  |
| **[Stochastic Subspace via Probabilistic Principal Component Analysis for Characterizing Model Error](http://arxiv.org/abs/2504.19963v2)** | 2025-05-06 | <details><summary>Show</summary><p>This paper proposes a probabilistic model of subspaces based on the probabilistic principal component analysis (PCA). Given a sample of vectors in the embedding space -- commonly known as a snapshot matrix -- this method uses quantities derived from the probabilistic PCA to construct distributions of the sample matrix, as well as the principal subspaces. It is applicable to projection-based reduced-order modeling methods, such as proper orthogonal decomposition and related model reduction methods. The stochastic subspace thus constructed can be used, for example, to characterize model-form uncertainty in computational mechanics. The proposed method has multiple desirable properties: (1) it is naturally justified by the probabilistic PCA and has analytic forms for the induced random matrix models; (2) it satisfies linear constraints, such as boundary conditions of all kinds, by default; (3) it has only one hyperparameter, which significantly simplifies training; and (4) its algorithm is very easy to implement. We demonstrate the performance of the proposed method via several numerical examples in computational mechanics and structural dynamics.</p></details> |  |
| **[Weighted balanced truncation method for approximating kernel functions by exponentials](http://arxiv.org/abs/2503.03183v2)** | 2025-05-06 | <details><summary>Show</summary><p>Kernel approximation with exponentials is useful in many problems with convolution quadrature and particle interactions such as integral-differential equations, molecular dynamics and machine learning. This paper proposes a weighted balanced truncation to construct an optimal model reduction method for compressing the number of exponentials in the sum-of-exponentials approximation of kernel functions. This method shows great promise in approximating long-range kernels, achieving over 4 digits of accuracy improvement for the Ewald-splitting and inverse power kernels in comparison with the classical balanced truncation. Numerical results demonstrate its excellent performance and attractive features for practical applications.</p></details> | 11 pages, 6 figures |
| **[$\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems by multivariate rational interpolation](http://arxiv.org/abs/2505.03057v1)** | 2025-05-05 | <details><summary>Show</summary><p>This paper addresses the $\mathcal{H}_2$-optimal approximation of linear dynamical systems with quadratic-output functions, also known as linear quadratic-output systems. Our major contributions are threefold. First, we derive interpolation-based first-order optimality conditions for the linear quadratic-output $\mathcal{H}_2$ minimization problem. These conditions correspond to the mixed-multipoint tangential interpolation of the full-order linear- and quadratic-output transfer functions, and generalize the Meier-Luenberger optimality framework for the $\mathcal{H}_2$-optimal model reduction of linear time-invariant systems. Second, given the interpolation data, we show how to enforce these mixed-multipoint tangential interpolation conditions explicitly by Petrov-Galerkin projection of the full-order model matrices. Third, to find the optimal interpolation data, we build on this projection framework and propose a generalization of the iterative rational Krylov algorithm for the $\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems, called LQO-IRKA. Upon convergence, LQO-IRKA produces a reduced linear quadratic-output system that satisfies the interpolatory optimality conditions. The method only requires solving shifted linear systems and matrix-vector products, thus making it suitable for large-scale problems. Numerical examples are included to illustrate the effectiveness of the proposed method.</p></details> |  |
| **[Steady-State Cascade Operators and their Role in Linear Control, Estimation, and Model Reduction Problems](http://arxiv.org/abs/2408.07568v2)** | 2025-05-01 | <details><summary>Show</summary><p>Certain linear matrix operators arise naturally in systems analysis and design problems involving cascade interconnections of linear time-invariant systems, including problems of stabilization, estimation, and model order reduction. We conduct here a comprehensive study of these operators and their relevant system-theoretic properties. The general theory is leveraged to delineate both known and new design methodologies for control and observation of cascades, and to characterize structural properties of reduced models. Several entirely new designs arise from this systematic categorization, including new recursive and low-gain design frameworks for observation of cascaded systems. The benefits of the results beyond the linear time-invariant setting are demonstrated through preliminary extensions for nonlinear systems, with an outlook towards the development of a similarly comprehensive nonlinear theory.</p></details> | <details><summary>16 pa...</summary><p>16 pages, 5 figures, revised version</p></details> |
| **[Generative Learning for Slow Manifolds and Bifurcation Diagrams](http://arxiv.org/abs/2504.20375v1)** | 2025-04-29 | <details><summary>Show</summary><p>In dynamical systems characterized by separation of time scales, the approximation of so called ``slow manifolds'', on which the long term dynamics lie, is a useful step for model reduction. Initializing on such slow manifolds is a useful step in modeling, since it circumvents fast transients, and is crucial in multiscale algorithms alternating between fine scale (fast) and coarser scale (slow) simulations. In a similar spirit, when one studies the infinite time dynamics of systems depending on parameters, the system attractors (e.g., its steady states) lie on bifurcation diagrams. Sampling these manifolds gives us representative attractors (here, steady states of ODEs or PDEs) at different parameter values. Algorithms for the systematic construction of these manifolds are required parts of the ``traditional'' numerical nonlinear dynamics toolkit. In more recent years, as the field of Machine Learning develops, conditional score-based generative models (cSGMs) have demonstrated capabilities in generating plausible data from target distributions that are conditioned on some given label. It is tempting to exploit such generative models to produce samples of data distributions conditioned on some quantity of interest (QoI). In this work, we present a framework for using cSGMs to quickly (a) initialize on a low-dimensional (reduced-order) slow manifold of a multi-time-scale system consistent with desired value(s) of a QoI (a ``label'') on the manifold, and (b) approximate steady states in a bifurcation diagram consistent with a (new, out-of-sample) parameter value. This conditional sampling can help uncover the geometry of the reduced slow-manifold and/or approximately ``fill in'' missing segments of steady states in a bifurcation diagram.</p></details> | <details><summary>17 pa...</summary><p>17 pages, 13 figures, 1 table</p></details> |
| **[Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction](http://arxiv.org/abs/2504.17655v1)** | 2025-04-24 | <details><summary>Show</summary><p>This paper presents a comprehensive empirical analysis of conformal prediction methods on a challenging aerial image dataset featuring diverse events in unconstrained environments. Conformal prediction is a powerful post-hoc technique that takes the output of any classifier and transforms it into a set of likely labels, providing a statistical guarantee on the coverage of the true label. Unlike evaluations on standard benchmarks, our study addresses the complexities of data-scarce and highly variable real-world settings. We investigate the effectiveness of leveraging pretrained models (MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to generate informative prediction sets. To further evaluate the impact of calibration, we consider two parallel pipelines (with and without temperature scaling) and assess performance using two key metrics: empirical coverage and average prediction set size. This setup allows us to systematically examine how calibration choices influence the trade-off between reliability and efficiency. Our findings demonstrate that even with relatively small labeled samples and simple nonconformity scores, conformal prediction can yield valuable uncertainty estimates for complex tasks. Moreover, our analysis reveals that while temperature scaling is often employed for calibration, it does not consistently lead to smaller prediction sets, underscoring the importance of careful consideration in its application. Furthermore, our results highlight the significant potential of model compression techniques within the conformal prediction pipeline for deployment in resource-constrained environments. Based on our observations, we advocate for future research to delve into the impact of noisy or ambiguous labels on conformal prediction performance and to explore effective model reduction strategies.</p></details> | <details><summary>17 pa...</summary><p>17 pages, 5 figures, and 2 tables</p></details> |
| **[On the Benefits of Memory for Modeling Time-Dependent PDEs](http://arxiv.org/abs/2409.02313v2)** | 2025-04-24 | <details><summary>Show</summary><p>Data-driven techniques have emerged as a promising alternative to traditional numerical methods for solving PDEs. For time-dependent PDEs, many approaches are Markovian -- the evolution of the trained system only depends on the current state, and not the past states. In this work, we investigate the benefits of using memory for modeling time-dependent PDEs: that is, when past states are explicitly used to predict the future. Motivated by the Mori-Zwanzig theory of model reduction, we theoretically exhibit examples of simple (even linear) PDEs, in which a solution that uses memory is arbitrarily better than a Markovian solution. Additionally, we introduce Memory Neural Operator (MemNO), a neural operator architecture that combines recent state space models (specifically, S4) and Fourier Neural Operators (FNOs) to effectively model memory. We empirically demonstrate that when the PDEs are supplied in low resolution or contain observation noise at train and test time, MemNO significantly outperforms the baselines without memory -- with up to 6x reduction in test error. Furthermore, we show that this benefit is particularly pronounced when the PDE solutions have significant high-frequency Fourier modes (e.g., low-viscosity fluid dynamics) and we construct a challenging benchmark dataset consisting of such PDEs.</p></details> |  |
| **[SUPRA: Subspace Parameterized Attention for Neural Operator on General Domains](http://arxiv.org/abs/2504.15897v1)** | 2025-04-22 | <details><summary>Show</summary><p>Neural operators are efficient surrogate models for solving partial differential equations (PDEs), but their key components face challenges: (1) in order to improve accuracy, attention mechanisms suffer from computational inefficiency on large-scale meshes, and (2) spectral convolutions rely on the Fast Fourier Transform (FFT) on regular grids and assume a flat geometry, which causes accuracy degradation on irregular domains. To tackle these problems, we regard the matrix-vector operations in the standard attention mechanism on vectors in Euclidean space as bilinear forms and linear operators in vector spaces and generalize the attention mechanism to function spaces. This new attention mechanism is fully equivalent to the standard attention but impossible to compute due to the infinite dimensionality of function spaces. To address this, inspired by model reduction techniques, we propose a Subspace Parameterized Attention (SUPRA) neural operator, which approximates the attention mechanism within a finite-dimensional subspace. To construct a subspace on irregular domains for SUPRA, we propose using the Laplacian eigenfunctions, which naturally adapt to domains' geometry and guarantee the optimal approximation for smooth functions. Experiments show that the SUPRA neural operator reduces error rates by up to 33% on various PDE datasets while maintaining state-of-the-art computational efficiency.</p></details> |  |

## Reduced Order Model
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Deep Learning for Subspace Regression](http://arxiv.org/abs/2509.23249v2)** | 2025-10-01 | <details><summary>Show</summary><p>It is often possible to perform reduced order modelling by specifying linear subspace which accurately captures the dynamics of the system. This approach becomes especially appealing when linear subspace explicitly depends on parameters of the problem. A practical way to apply such a scheme is to compute subspaces for a selected set of parameters in the computationally demanding offline stage and in the online stage approximate subspace for unknown parameters by interpolation. For realistic problems the space of parameters is high dimensional, which renders classical interpolation strategies infeasible or unreliable. We propose to relax the interpolation problem to regression, introduce several loss functions suitable for subspace data, and use a neural network as an approximation to high-dimensional target function. To further simplify a learning problem we introduce redundancy: in place of predicting subspace of a given dimension we predict larger subspace. We show theoretically that this strategy decreases the complexity of the mapping for elliptic eigenproblems with constant coefficients and makes the mapping smoother for general smooth function on the Grassmann manifold. Empirical results also show that accuracy significantly improves when larger-than-needed subspaces are predicted. With the set of numerical illustrations we demonstrate that subspace regression can be useful for a range of tasks including parametric eigenproblems, deflation techniques, relaxation methods, optimal control and solution of parametric partial differential equations.</p></details> |  |
| **[An Adaptive CUR Algorithm and its Application to Reduced-Order Modeling of Random PDEs](http://arxiv.org/abs/2509.21480v2)** | 2025-09-30 | <details><summary>Show</summary><p>Certain classes of CUR algorithms, also referred to as cross or pseudoskeleton algorithms, are widely used for low-rank matrix approximation when direct access to all matrix entries is costly. Their key advantage lies in constructing a rank-r approximation by sampling only r columns and r rows of the target matrix. This property makes them particularly attractive for reduced-order modeling of nonlinear matrix differential equations, where nonlinear operations on low-rank matrices can otherwise produce high-rank or even full-rank intermediates that must subsequently be truncated to rank $r$. CUR cross algorithms bypass the intermediate step and directly form the rank-$r$ matrix. However, standard cross algorithms may suffer from loss of accuracy in some settings, limiting their robustness and broad applicability. In this work, we propose a cross oversampling algorithm that augments the intersection with additional sampled columns and rows. We provide an error analysis demonstrating that the proposed oversampling improves robustness. We also present an algorithm that adaptively selects the number of oversampling entries based on efficiently computable indicators. We demonstrate the performance of the proposed CUR algorithm for time integration of several nonlinear stochastic PDEs on low-rank matrix manifolds.</p></details> |  |
| **[Reservoir computing based predictive reduced order model for steel grade intermixing in an industrial continuous casting tundish](http://arxiv.org/abs/2509.26293v1)** | 2025-09-30 | <details><summary>Show</summary><p>Continuous casting is a widely adopted process in the steel industry, where maintaining high steel quality is paramount. Efficient prediction of grade intermixing during ladle changeover operations is critical for maintaining steel quality and minimizing material losses in the continuous casting process. Among various factors influencing grade intermixing, operating parameters play a significant role, in addition to tundish geometry and flow control devices. In this study, three-dimensional, transient, two-phase turbulent flow simulations are conducted to investigate the ladle changeover operation. During this process, the molten steel level in the tundish typically varies over time, significantly affecting the grade intermixing phenomena. The influence of ladle change time on intermixing time has been presented. However, high-fidelity full-order simulations of such complex transient phenomena are computationally expensive and are impractical for real-time monitoring or design-space exploration in industrial-scale applications. To address this issue, a reduced order modelling approach based on proper orthogonal decomposition (POD) and reservoir computing (RC) is employed to efficiently predict intermixing time. The proposed reduced order model (ROM) demonstrates excellent predictive accuracy using limited training data while requiring significantly less computational resources and training time. The results demonstrate the potential of the proposed methodology as a fast, reliable tool for real-time process monitoring and optimization in industrial continuous casting operations.</p></details> |  |
| **[Interpolated Adaptive Linear Reduced Order Modeling for Deformation Dynamics](http://arxiv.org/abs/2509.25392v1)** | 2025-09-29 | <details><summary>Show</summary><p>Linear reduced-order modeling (ROM) is widely used for efficient simulation of deformation dynamics, but its accuracy is often limited by the fixed linearization of the reduced mapping. We propose a new adaptive strategy for linear ROM that allows the reduced mapping to vary dynamically in response to the evolving deformation state, significantly improving accuracy over traditional linear approaches. To further handle large deformations, we introduce a historical displacement basis combined with Grassmann interpolation, enabling the system to recover robustly even in challenging scenarios. We evaluate our method through quantitative online-error analysis and qualitative comparisons with principal component analysis (PCA)-based linear ROM simulations, demonstrating substantial accuracy gains while preserving comparable computational costs.</p></details> |  |

## Dynamical System
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Nonlinear Framework for Speech Bandwidth Extension](http://arxiv.org/abs/2507.15970v2)** | 2025-10-01 | <details><summary>Show</summary><p>Recovering high-frequency components lost to bandwidth constraints is crucial for applications ranging from telecommunications to high-fidelity audio on limited resources. We introduce NDSI-BWE, a new adversarial Band Width Extension (BWE) framework that leverage four new discriminators inspired by nonlinear dynamical system to capture diverse temporal behaviors: a Multi-Resolution Lyapunov Discriminator (MRLD) for determining sensitivity to initial conditions by capturing deterministic chaos, a Multi-Scale Recurrence Discriminator (MS-RD) for self-similar recurrence dynamics, a Multi-Scale Detrended Fractal Analysis Discriminator (MSDFA) for long range slow variant scale invariant relationship, a Multi-Resolution Poincar\'e Plot Discriminator (MR-PPD) for capturing hidden latent space relationship, a Multi-Period Discriminator (MPD) for cyclical patterns, a Multi-Resolution Amplitude Discriminator (MRAD) and Multi-Resolution Phase Discriminator (MRPD) for capturing intricate amplitude-phase transition statistics. By using depth-wise convolution at the core of the convolutional block with in each discriminators, NDSI-BWE attains an eight-times parameter reduction. These seven discriminators guide a complex-valued ConformerNeXt based genetor with a dual stream Lattice-Net based architecture for simultaneous refinement of magnitude and phase. The genertor leverage the transformer based conformer's global dependency modeling and ConvNeXt block's local temporal modeling capability. Across six objective evaluation metrics and subjective based texts comprises of five human judges, NDSI-BWE establishes a new SoTA in BWE.</p></details> |  |
| **[Rapid training of Hamiltonian graph networks using random features](http://arxiv.org/abs/2506.06558v2)** | 2025-10-01 | <details><summary>Show</summary><p>Learning dynamical systems that respect physical symmetries and constraints remains a fundamental challenge in data-driven modeling. Integrating physical laws with graph neural networks facilitates principled modeling of complex N-body dynamics and yields accurate and permutation-invariant models. However, training graph neural networks with iterative, gradient-based optimization algorithms (e.g., Adam, RMSProp, LBFGS) often leads to slow training, especially for large, complex systems. In comparison to 15 different optimizers, we demonstrate that Hamiltonian Graph Networks (HGN) can be trained up to 600x faster--but with comparable accuracy--by replacing iterative optimization with random feature-based parameter construction. We show robust performance in diverse simulations, including N-body mass-spring and molecular systems in up to 3 dimensions and 10,000 particles with different geometries, while retaining essential physical invariances with respect to permutation, rotation, and translation. Our proposed approach is benchmarked using a NeurIPS 2022 Datasets and Benchmarks Track publication to further demonstrate its versatility. We reveal that even when trained on minimal 8-node systems, the model can generalize in a zero-shot manner to systems as large as 4096 nodes without retraining. Our work challenges the dominance of iterative gradient-descent-based optimization algorithms for training neural network models for physical systems.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 6 figures, 3 tables, and an appendix</p></details> |
| **[Training-Free Data Assimilation with GenCast](http://arxiv.org/abs/2509.18811v2)** | 2025-10-01 | <details><summary>Show</summary><p>Data assimilation is widely used in many disciplines such as meteorology, oceanography, and robotics to estimate the state of a dynamical system from noisy observations. In this work, we propose a lightweight and general method to perform data assimilation using diffusion models pre-trained for emulating dynamical systems. Our method builds on particle filters, a class of data assimilation algorithms, and does not require any further training. As a guiding example throughout this work, we illustrate our methodology on GenCast, a diffusion-based model that generates global ensemble weather forecasts.</p></details> |  |
| **[Propagating Model Uncertainty through Filtering-based Probabilistic Numerical ODE Solvers](http://arxiv.org/abs/2503.04684v2)** | 2025-10-01 | <details><summary>Show</summary><p>Filtering-based probabilistic numerical solvers for ordinary differential equations (ODEs), also known as ODE filters, have been established as efficient methods for quantifying numerical uncertainty in the solution of ODEs. In practical applications, however, the underlying dynamical system often contains uncertain parameters, requiring the propagation of this model uncertainty to the ODE solution. In this paper, we demonstrate that ODE filters, despite their probabilistic nature, do not automatically solve this uncertainty propagation problem. To address this limitation, we present a novel approach that combines ODE filters with numerical quadrature to properly marginalize over uncertain parameters, while accounting for both parameter uncertainty and numerical solver uncertainty. Experiments across multiple dynamical systems demonstrate that the resulting uncertainty estimates closely match reference solutions. Notably, we show how the numerical uncertainty from the ODE solver can help prevent overconfidence in the propagated uncertainty estimates, especially when using larger step sizes. Our results illustrate that probabilistic numerical methods can effectively quantify both numerical and parametric uncertainty in dynamical systems.</p></details> |  |

